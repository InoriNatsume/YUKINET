<!doctype html>
<html lang="ko"><head>
<meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/>
<title>Symbol Wiki: Xi_k</title>
<link rel="stylesheet" href="../assets/style.css"/>
<script>
window.MathJax={
  tex:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$'],['\\[','\\]']]},
  options:{skipHtmlTags:['script','noscript','style','textarea','pre','code']}
};
</script>
<script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
</head><body><div class="wrap"><article class="paper"><div class="topnav"><a class="btn" href="index.html">기호 위키 인덱스</a><a class="btn" href="../index.html#notation">최상위 문서(기호 탭)</a></div><h1>Symbol: $\xi_k$</h1><p class='muted'><strong>잡음 확률변수 (Noise random variable)</strong></p><h2>모티베이션 (Motivation)</h2><p>$\xi_k$는 $k$번째 step에서 실제로 뽑히는 난수(노이즈) 확률변수다. 코드에서 <code>torch.randn_like(x)</code> 같은 호출로 생성되는 텐서를 수학적으로 부르면 $\xi_k$에 해당한다.</p><ol class='list'><li>ComfyUI에서는 sampler에 따라 난수가 ‘초기 한 번’만 쓰이기도 하고(결정론 계열), step마다 추가로 주입되기도 한다(ancestral/SDE). 이때 step별 난수를 기호로 분리해 두면, “왜 어떤 sampler는 결과가 더 랜덤하게 흔들리는가”가 $\xi_k$의 사용 방식 차이로 정리된다.</li><li><code>eta</code>, <code>s_noise</code>, <code>s_churn</code> 같은 파라미터는 실무적으로 “$\xi_k$를 얼마나 강하게 섞을지”를 조절하는 손잡이에 가깝다. 즉 질감/다양성/안정성(특히 영상의 깜빡임)을 튜닝할 때, 결국 $\xi_k$가 들어가는 항의 스케일을 만지는 셈이다.</li><li>inpaint에서는 보통 마스크 영역에만 노이즈를 주입하고 나머지는 고정하는데, 이는 $\xi_k$를 마스크로 곱해 부분적으로만 작동시키는 것과 같다. 따라서 ‘어디에 랜덤성을 남길지’는 $\xi_k$ 설계(및 $\mathcal{K}$ 제약)와 직접 연결된다.</li><li>기본 가정(i.i.d. 표준정규)을 바꾸면 결과 분포가 달라진다. 예를 들어 프레임 간 상관 노이즈(영상), 저주파/컬러드 노이즈, 또는 비정규 노이즈를 쓰면 질감과 안정성이 달라질 수 있고, 그 변화는 결국 $\xi_k$의 분포/상관 구조 변화로 설명된다.</li><li>재현성과 중간 재개(continue sampling)를 제대로 하려면, RNG state를 보존하거나 $\xi_0,\dots,\xi_{k-1}$의 소비 순서를 일관되게 유지해야 한다. 그렇지 않으면 같은 seed라도 “어느 step에서 어떤 $\xi_k$가 뽑혔는가”가 달라져 결과가 어긋난다.</li></ol><h2>엄밀 정의 (Formal Definitions)</h2><div class='box'><p class='small'><strong>정의 1.</strong></p><div class='formula'>$$ \xi_k:(\Omega,\mathcal{F},\mathbb{P})\to(\mathbb{R}^d,\mathcal{B}(\mathbb{R}^d)) $$</div></div><div class='box'><p class='small'><strong>정의 2.</strong></p><div class='formula'>$$ \xi_k\sim\mathcal{N}(0,I_d),\quad \text{i.i.d.} $$</div></div><h2>정의 해설 (Commentary)</h2><h3>해설(요약) (Summary)</h3><p>첫 문장은 $\xi_k$가 “확률공간에서 값공간으로 가는 함수”라는 뜻이다. 즉 $\omega$가 정해지면(난수 시나리오가 하나 선택되면) $\xi_k(\omega)$라는 구체 난수 벡터가 정해진다.</p><p>둘째 문장은 분포 가정이다. 대부분의 diffusion sampling에서는 각 step에서 표준정규를 독립으로 뽑는다(평균 0, 공분산 $I_d$).</p><p>이 가정이 바뀌면(예: 상관 노이즈, 비정규 노이즈) 결과 경로의 분산 구조가 달라지고, 이론적 해석도 바뀐다.</p><div class='box'><p class='small'><strong>정의 1.</strong></p><div class='formula'>$$ \xi_k:(\Omega,\mathcal{F},\mathbb{P})\to(\mathbb{R}^d,\mathcal{B}(\mathbb{R}^d)) $$</div><h3>해설</h3><ol class='list'><li>표본공간의 원소 $\omega$는 ‘난수의 전체 시나리오’다. $\xi_k(\omega)$는 그 시나리오에서 $k$번째로 뽑힌 난수 벡터다.</li><li>값공간이 $\mathbb{R}^d$인 이유는 상태 $x_k\in\mathbb{R}^d$에 더해지려면 차원이 맞아야 하기 때문이다.</li></ol><h3>직관(정의와 연결)</h3><ol class='list'><li>코드에서 난수를 한 번 뽑아 텐서로 받는 그 값이 $\xi_k$의 실현값이다.</li></ol><h3>수치 예시</h3><ol class='list'><li>$d=2$에서 $\xi_k(\omega)=(0.31,-1.24)$ 같은 값이 가능하다.</li></ol></div><div class='box'><p class='small'><strong>정의 2.</strong></p><div class='formula'>$$ \xi_k\sim\mathcal{N}(0,I_d),\quad \text{i.i.d.} $$</div><h3>해설</h3><ol class='list'><li>표준정규는 평균 0, 공분산이 항등행렬이라는 뜻이다: $\mathbb{E}[\xi_k]=0$, $\mathrm{Cov}(\xi_k)=I_d$.</li><li>i.i.d.는 서로 다른 step의 노이즈가 독립이고 동일한 분포를 따른다는 뜻이다.</li></ol><h3>직관(정의와 연결)</h3><ol class='list'><li>‘매 step 새로 뽑는 랜덤’이고, 과거 노이즈와 상관이 없다고 보는 것이 기본 모델이다.</li></ol><h3>수치 예시</h3><ol class='list'><li>$d=1$에서 $\xi_0=0.5$, $\xi_1=-1.2$, $\xi_2=0.1$처럼 서로 다른 값이 독립적으로 나온다고 가정한다.</li></ol></div><h2>직관(요약) (Intuition)</h2><ol class='list'><li>각 step마다 새로 뽑아 넣는 ‘랜덤 흔들림 벡터’다.</li><li>같은 seed를 쓰면 $\xi_k$의 실현값이 재현돼 결과가 반복된다.</li><li>ComfyUI에서 deterministic sampler는 초기 노이즈만으로 경로가 결정되고, step별 추가 난수를 쓰지 않는다. 반면 ancestral/SDE sampler는 매 step에 $\xi_k$가 들어가므로, 같은 <code>seed</code>라도 ‘추가 난수 사용 방식’이 바뀌면 결과가 달라질 수 있다(예: churn 구간에서만 뽑기).</li></ol><h2>구체 원소 예시(모음) (Concrete Examples)</h2><ol class='list'><li>(1차원) $\xi_k\sim\mathcal{N}(0,1)$에서 한 번 뽑았더니 $\xi_k=-0.73$이 나왔다고 하자(실현값).</li><li>(2차원) $\xi_k=(0.31,-1.24)\in\mathbb{R}^2$ 같은 벡터도 실현값이 될 수 있다.</li><li>(스케일링 예) $d=3$에서 $\xi_k=(0.2,-0.1,1.5)$를 뽑고 스케일 0.4를 곱하면 주입 노이즈는 $(0.08,-0.04,0.6)$이 된다.</li></ol><h2>코드 대응 (Code Mapping)</h2><ol class='list'><li><code>noise_sampler(...)</code>, <code>torch.randn_like(x)</code>로 생성되는 텐서.</li></ol><h2>자주 헷갈리는 점 (Pitfalls)</h2><ol class='list'><li>독립 가정을 깨는 상관 난수를 쓰면 이론적 분산식이 바뀐다.</li></ol><h2>관련 기호 (Related Symbols)</h2><div class='topnav'><a class="btn" href="Omega_F_P.html">$(\Omega,\mathcal{F},\mathbb{P})$</a><a class="btn" href="Fk.html">$\mathcal{F}_k$</a><a class="btn" href="Phi_k.html">$\Phi_k$</a></div><div class="topnav"><a class="btn" href="Omega_F_P.html">이전: $(\Omega,\mathcal{F},\mathbb{P})$</a><a class="btn" href="Fk.html">다음: $\mathcal{F}_k$</a></div></article></div></body></html>