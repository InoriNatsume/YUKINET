<!doctype html><html lang='ko'><head><meta charset='UTF-8'/><meta name='viewport' content='width=device-width, initial-scale=1.0'/><title>Diffusion Training Master Docs</title><link rel='stylesheet' href='assets/style.css'/><script>window.MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$'],['\\[','\\]']]},options:{skipHtmlTags:['script','noscript','style','textarea','pre','code']}};</script><script async src='https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js'></script></head><body><div class='wrap'><article class='paper'>
<div id="top"></div>
<p class="small">ë¬¸ì„œ ê³„ì¸µ: <code>training_site/index.html</code> (ìµœìƒìœ„) â†’ ê°œë³„ optimizer / hyperparameter / architecture í˜ì´ì§€</p>
<h1>Diffusion Training Master Docs</h1>
<p class="muted">sd-scripts Â· diffusion-pipe Â· DiffSynth-Studio ì„¸ ì½”ë“œë² ì´ìŠ¤ì˜ í›ˆë ¨ íŒŒë¼ë¯¸í„°, ì˜µí‹°ë§ˆì´ì €, ì•„í‚¤í…ì²˜ë¥¼ ìˆ˜í•™ê³¼ ì½”ë“œë¡œ í†µí•© ì •ë¦¬í•©ë‹ˆë‹¤.</p>
<div class="chips">
  <span class="chip">ì˜µí‹°ë§ˆì´ì €: 30+</span>
  <span class="chip">ì•„í‚¤í…ì²˜: 25+</span>
  <span class="chip">í›ˆë ¨ ëª¨ë“œ: Fine-tune / LoRA / DreamBooth / ControlNet / TI</span>
  <span class="chip">ì½”ë“œë² ì´ìŠ¤: 3</span>
</div>
<div class="compare-header">
  <div class="legend">
    <span><span class="dot sd"></span> sd-scripts</span>
    <span><span class="dot dp"></span> diffusion-pipe</span>
    <span><span class="dot ds"></span> DiffSynth-Studio</span>
  </div>
</div>

<div class="tabs" data-tab-group="master">
  <button class="tab-btn active" data-tab-group="master" data-tab-target="math-foundation">0) í›ˆë ¨ ìˆ˜í•™ ê¸°ì´ˆ</button>
  <button class="tab-btn" data-tab-group="master" data-tab-target="training-loop">1) í†µí•© í›ˆë ¨ ë£¨í”„</button>
  <button class="tab-btn" data-tab-group="master" data-tab-target="optimizer-catalog">2) Optimizer Catalog</button>
  <button class="tab-btn" data-tab-group="master" data-tab-target="lr-scheduler">3) LR Scheduler</button>
  <button class="tab-btn" data-tab-group="master" data-tab-target="loss-catalog">4) Loss &amp; Weighting</button>
  <button class="tab-btn" data-tab-group="master" data-tab-target="arch-catalog">5) Architecture Catalog</button>
  <button class="tab-btn" data-tab-group="master" data-tab-target="hyperparams">6) Hyperparameter ë¸Œë¦¬ì§€</button>
  <button class="tab-btn" data-tab-group="master" data-tab-target="memory-opt">7) ë©”ëª¨ë¦¬ ìµœì í™”</button>
  <button class="tab-btn" data-tab-group="master" data-tab-target="code-map">8) ì½”ë“œ ë§¤í•‘</button>
</div>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<!-- TAB 0: í›ˆë ¨ ìˆ˜í•™ ê¸°ì´ˆ -->
<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<section id="math-foundation" class="tab-panel active" data-tab-group="master">
<h2>0) í›ˆë ¨ ìˆ˜í•™ ê¸°ì´ˆ â€” Diffusion Trainingì˜ ì¸¡ë„ë¡ ì  ê¸°ë°˜</h2>
<p>ì¶”ë¡ (sampling)ì´ ì—­ë°©í–¥ SDE/ODEë¥¼ í’€ì–´ $p_\text{data}$ë¥¼ ë³µì›í•˜ëŠ” ì¼ì´ë¼ë©´, <strong>í›ˆë ¨</strong>ì€ ëª¨ë¸ $\theta$ë¥¼ ìµœì í™”í•˜ì—¬ ì •ë°©í–¥ í™•ì‚° ê³¼ì •ì˜ score/velocityë¥¼ í•™ìŠµí•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ê° ì„¹ì…˜ì—ì„œëŠ” ìˆ˜í•™ì  ì •ì˜ì™€ í•¨ê»˜ <strong>ì™œ ê·¸ ìˆ˜ì‹ì´ í•„ìš”í•œì§€(ëª¨í‹°ë² ì´ì…˜)</strong>, ê·¸ë¦¬ê³  ê·¸ê²ƒì´ <strong>ì‹¤ì œ ì½”ë“œì˜ ì–´ë–¤ ì¤„ì— ëŒ€ì‘í•˜ëŠ”ì§€</strong>ë¥¼ í•¨ê»˜ ì„¤ëª…í•©ë‹ˆë‹¤.</p>

<div class="tabs mini" data-tab-group="math-sub">
  <button class="tab-btn active" data-tab-group="math-sub" data-tab-target="math-a">A. ì •ë°©í–¥ í™•ì‚°</button>
  <button class="tab-btn" data-tab-group="math-sub" data-tab-target="math-b">B. í›ˆë ¨ ëª©ì í•¨ìˆ˜</button>
  <button class="tab-btn" data-tab-group="math-sub" data-tab-target="math-c">C. Flow Matching</button>
  <button class="tab-btn" data-tab-group="math-sub" data-tab-target="math-d">D. ìµœì í™” ì´ë¡ </button>
  <button class="tab-btn" data-tab-group="math-sub" data-tab-target="math-e">E. ê¸°í˜¸ ì‚¬ì „</button>
</div>

<section id="math-a" class="tab-panel active" data-tab-group="math-sub">
<h3>A. ì •ë°©í–¥ í™•ì‚° ê³¼ì • (Forward Process)</h3>

<div class="box" style="border-left:3px solid var(--accent);margin-bottom:16px">
<h4 style="margin-top:0">ğŸ¯ ëª¨í‹°ë² ì´ì…˜: ì™œ ë°ì´í„°ì— ë…¸ì´ì¦ˆë¥¼ ë”í•˜ëŠ”ê°€?</h4>
<p><strong>ìˆ˜í•™ì  ê´€ì :</strong> ìš°ë¦¬ì˜ ëª©í‘œëŠ” ë³µì¡í•œ ë°ì´í„° ë¶„í¬ $p_\text{data}(x)$ë¥¼ <em>ë‹¤ë£¨ê¸° ì‰¬ìš´</em> ë¶„í¬ $\mathcal{N}(0,I)$ë¡œ ë³€í™˜í•˜ëŠ” ë§¤í•‘ì„ í•™ìŠµí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì§ì ‘ $p_\text{data}\to\mathcal{N}$ì„ ë°°ìš°ëŠ” ê²ƒì€ ë§¤ìš° ì–´ë µì§€ë§Œ, ì ì§„ì ìœ¼ë¡œ ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€í•˜ì—¬ $x_0\to x_1\to\cdots\to x_T\approx\mathcal{N}$ìœ¼ë¡œ ë³€í™˜í•˜ë©´ ê° ìŠ¤í…ì˜ ì—­ë³€í™˜ $p(x_{t-1}|x_t)$ì´ ê°€ìš°ì‹œì•ˆìœ¼ë¡œ ê·¼ì‚¬ ê°€ëŠ¥í•´ì§‘ë‹ˆë‹¤ (Feller, 1949).</p>
<p><strong>í›ˆë ¨ ê´€ì :</strong> ì •ë°©í–¥ í™•ì‚°ì€ ëª¨ë¸ì´ <em>í’€ì–´ì•¼ í•  ë¬¸ì œ</em>ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. $x_0$(ì›ë³¸ ì´ë¯¸ì§€)ì™€ $\epsilon$(ìˆœìˆ˜ ë…¸ì´ì¦ˆ) ì‚¬ì´ì˜ ëª¨ë“  ë…¸ì´ì¦ˆ ë ˆë²¨ì—ì„œ ëª¨ë¸ì´ "ë¬´ì—‡ì´ ì‹ í˜¸ì´ê³  ë¬´ì—‡ì´ ë…¸ì´ì¦ˆì¸ì§€" êµ¬ë¶„í•˜ë„ë¡ í•™ìŠµì‹œí‚µë‹ˆë‹¤. ë‹¤ì–‘í•œ ë…¸ì´ì¦ˆ ìˆ˜ì¤€ì„ ê²½í—˜í•´ì•¼ ì €ë…¸ì´ì¦ˆ(ì„¸ë°€í•œ ë””í…Œì¼)ë¶€í„° ê³ ë…¸ì´ì¦ˆ(ì „ì²´ êµ¬ì¡°)ê¹Œì§€ ëª¨ë‘ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
</div>

<h4>DDPM ì´ì‚° ì •ë°©í–¥ â€” ë§ˆë¥´ì½”í”„ ì²´ì¸</h4>
<p>DDPM (Ho et al., 2020)ì€ $T$ê°œì˜ ì´ì‚° ìŠ¤í…ìœ¼ë¡œ êµ¬ì„±ëœ ë§ˆë¥´ì½”í”„ ì²´ì¸ìœ¼ë¡œ ì •ë°©í–¥ ê³¼ì •ì„ ì •ì˜í•©ë‹ˆë‹¤:</p>
<div class="formula">$$q(x_{1:T}|x_0)=\prod_{t=1}^T q(x_t|x_{t-1}),\qquad q(x_t|x_{t-1})=\mathcal{N}(x_t;\sqrt{1-\beta_t}\,x_{t-1},\beta_t I)$$</div>
<p><strong>í•µì‹¬ ì„±ì§ˆ:</strong> ë§ˆë¥´ì½”í”„ ì²´ì¸ì˜ ëˆ„ì  ê³± ë•ë¶„ì— ì¤‘ê°„ ìŠ¤í…ì„ ê±°ì¹˜ì§€ ì•Šê³  <em>ì„ì˜ì˜ $t$ì—ì„œ ì§ì ‘ ìƒ˜í”Œ</em>í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:</p>
<div class="formula">$$q(x_t|x_0)=\mathcal{N}\!\left(x_t;\;\sqrt{\bar\alpha_t}\,x_0,\;(1-\bar\alpha_t)I\right)$$</div>
<div class="formula">$$\boxed{x_t=\sqrt{\bar\alpha_t}\,x_0+\sqrt{1-\bar\alpha_t}\,\epsilon,\quad\epsilon\sim\mathcal{N}(0,I)}$$</div>
<p>ì—¬ê¸°ì„œ $\bar\alpha_t=\prod_{s=1}^t(1-\beta_s)$ëŠ” ëˆ„ì  ì‹ í˜¸ ë³´ì¡´ìœ¨ì´ë©°, $\beta_t$ëŠ” ë…¸ì´ì¦ˆ ìŠ¤ì¼€ì¤„(linear, cosine ë“±)ë¡œ ì œì–´í•©ë‹ˆë‹¤.</p>

<div class="codebox"># sd-scripts: library/train_util.py â€” DDPM ì •ë°©í–¥ ê³¼ì • êµ¬í˜„
# Î±_bar ê³„ì‚°
alphas = 1.0 - betas                     # Î±_t = 1 - Î²_t
alphas_cumprod = torch.cumprod(alphas, dim=0)  # á¾±_t = Î (Î±_s)

# ì„ì˜ timestep tì—ì„œ noisy sample ìƒì„±
sqrt_alpha = alphas_cumprod[t] ** 0.5          # âˆšá¾±_t (signal coefficient)
sqrt_one_minus_alpha = (1 - alphas_cumprod[t]) ** 0.5  # âˆš(1-á¾±_t) (noise coefficient)
x_t = sqrt_alpha * x_0 + sqrt_one_minus_alpha * noise  # ì •ë°©í–¥ í™•ì‚° í•µì‹¬ í•œ ì¤„</div>

<p><strong>ì§ê´€:</strong> $t$ê°€ ì¦ê°€í•˜ë©´ $\bar\alpha_t\to 0$ì´ë¯€ë¡œ $x_t\to\epsilon$. ì¦‰ ì›ë³¸ ì‹ í˜¸ê°€ ì ì§„ì ìœ¼ë¡œ ì‚¬ë¼ì§€ê³  ìˆœìˆ˜ ë…¸ì´ì¦ˆë§Œ ë‚¨ìŠµë‹ˆë‹¤. $t=0$ì´ë©´ $x_0$ ê·¸ëŒ€ë¡œ, $t=T$ì´ë©´ ê±°ì˜ ìˆœìˆ˜ ê°€ìš°ì‹œì•ˆ.</p>

<h4>ì—°ì† ì‹œê°„ SDE í˜•íƒœ</h4>
<p>ì´ì‚° ê³¼ì •ì„ ì—°ì†ìœ¼ë¡œ í™•ì¥í•˜ë©´ <strong>í™•ë¥  ë¯¸ë¶„ ë°©ì •ì‹(SDE)</strong>ìœ¼ë¡œ í‘œí˜„ë©ë‹ˆë‹¤ (Song et al., 2021):</p>
<div class="formula">$$dx=f(x,t)\,dt+g(t)\,dW_t$$</div>
<p>DDPMì˜ ê²½ìš° VP-SDE(Variance Preserving):</p>
<div class="formula">$$dx=-\frac{\beta(t)}{2}x\,dt+\sqrt{\beta(t)}\,dW_t$$</div>
<p class="small">$f(x,t)=-\frac{\beta(t)}{2}x$ëŠ” drift(ì‹ í˜¸ ê°ì‡ ), $g(t)=\sqrt{\beta(t)}$ëŠ” diffusion(ë…¸ì´ì¦ˆ ì£¼ì…). Andersonì˜ ì—­ì‹œê°„ SDE ì •ë¦¬ì— ì˜í•´ ì—­ë°©í–¥ SDEëŠ” <strong>score function</strong> $\nabla_x\log p_t(x)$ë§Œ ì•Œë©´ í’€ ìˆ˜ ìˆê³ , ì´ê²ƒì´ í›ˆë ¨ì˜ ëª©í‘œì…ë‹ˆë‹¤.</p>

<h4>Flow Matching ì—°ì† ì •ë°©í–¥ â€” Optimal Transport Path</h4>
<div class="box" style="border-left:3px solid #007bff;margin-bottom:16px">
<p><strong>ëª¨í‹°ë² ì´ì…˜:</strong> DDPMì˜ SDE ê²½ë¡œëŠ” ê³¡ì„ ì´ë¼ ë§ì€ ì¶”ë¡  ìŠ¤í…ì´ í•„ìš”í•©ë‹ˆë‹¤. Flow Matching (Lipman et al., 2022)ì€ $x_0$ì—ì„œ $\epsilon$ê¹Œì§€ì˜ <strong>ì§ì„ (optimal transport) ê²½ë¡œ</strong>ë¥¼ ì‚¬ìš©í•˜ì—¬ ë” íš¨ìœ¨ì ì¸ í•™ìŠµê³¼ ë¹ ë¥¸ ì¶”ë¡ ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ì§ì„  ê²½ë¡œëŠ” <em>êµì°¨í•˜ì§€ ì•Šì•„</em> í•™ìŠµì´ ì•ˆì •ì ì´ê³ , ì ì€ NFE(Number of Function Evaluations)ë¡œ ê³ í’ˆì§ˆ ìƒ˜í”Œì„ ìƒì„±í•©ë‹ˆë‹¤.</p>
</div>
<div class="formula">$$\boxed{x_t=(1-t)\,x_0+t\,\epsilon,\quad t\in[0,1]}$$</div>
<div class="formula">$$v_t=\frac{dx_t}{dt}=\epsilon-x_0 \quad\text{(ìƒìˆ˜ velocity â€” ê²½ë¡œê°€ ì§ì„ )}$$</div>
<p><strong>ODE í˜•íƒœ:</strong> Flow Matchingì€ SDEê°€ ì•„ë‹Œ <strong>í™•ë¥  íë¦„ ODE</strong>ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤:</p>
<div class="formula">$$\frac{dx_t}{dt}=v_\theta(x_t,t)\qquad\text{(í•™ìŠµëœ velocity field)}$$</div>

<div class="codebox"># sd-scripts: flux_train.py â€” Flow Matching ì •ë°©í–¥
# tëŠ” [0,1] ë²”ìœ„ì˜ ì—°ì† ì‹œê°„, sigmoid/logit-normal ë“±ìœ¼ë¡œ ìƒ˜í”Œë§
noisy_x = (1.0 - t) * x_0 + t * noise   # ì§ì„  ë³´ê°„ (linear interpolation)
target = noise - x_0                      # velocity target (ìƒìˆ˜!)

# diffusion-pipe: models/flux.py â€” ë™ì¼ êµ¬ì¡°
x_t = (1 - sigma) * latent + sigma * noise  # sigma = t
velocity_target = noise - latent

# DiffSynth-Studio: diffsynth/trainers/text_to_image.py
noisy_latent = (1 - t) * latent + t * noise
loss = F.mse_loss(model_pred, noise - latent)  # velocity matching</div>

<h4>DDPM vs Flow Matching ì •ë°©í–¥ ë¹„êµ</h4>
<table>
  <thead><tr><th>íŠ¹ì„±</th><th>DDPM</th><th>Flow Matching</th></tr></thead>
  <tbody>
    <tr><td><strong>ìˆ˜í•™ì  í”„ë ˆì„ì›Œí¬</strong></td><td>ì´ì‚° ë§ˆë¥´ì½”í”„ ì²´ì¸ / VP-SDE</td><td>ì—°ì† ODE / Optimal Transport</td></tr>
    <tr><td><strong>ê²½ë¡œ í˜•íƒœ</strong></td><td>ê³¡ì„  (variance preserving)</td><td>ì§ì„  (constant velocity)</td></tr>
    <tr><td><strong>ë³´ê°„ ê³µì‹</strong></td><td>$\sqrt{\bar\alpha_t}\,x_0+\sqrt{1-\bar\alpha_t}\,\epsilon$</td><td>$(1-t)x_0+t\epsilon$</td></tr>
    <tr><td><strong>í•„ìš” ì¶”ë¡  ìŠ¤í…</strong></td><td>20~50+ (DDPM/DDIM)</td><td>1~4 (Euler)</td></tr>
    <tr><td><strong>ì‚¬ìš© ëª¨ë¸</strong></td><td>SD 1.x, SDXL</td><td>Flux, SD3, Wan, Lumina</td></tr>
    <tr><td><strong>ì½”ë“œ ìœ„ì¹˜ (sd-scripts)</strong></td><td><code>train_util.py â†’ add_noise()</code></td><td><code>flux_train.py</code> ë£¨í”„ ë‚´ë¶€</td></tr>
  </tbody>
</table>

<h4>SNR (Signal-to-Noise Ratio) â€” ëª¨ë“  ê°€ì¤‘ì¹˜ ê¸°ë²•ì˜ ê¸°ì´ˆ</h4>
<div class="formula">$$\text{SNR}(t)=\frac{\bar\alpha_t}{1-\bar\alpha_t}=\frac{\text{signal power}}{\text{noise power}}$$</div>

<div class="box" style="border-left:3px solid #ffc107;margin-bottom:16px">
<p><strong>ì™œ SNRì´ ì¤‘ìš”í•œê°€?</strong> ë‹¨ìˆœ MSE ì†ì‹¤ $\|\epsilon_\theta-\epsilon\|^2$ì„ ì‚¬ìš©í•˜ë©´, ê° timestepì—ì„œì˜ ê¸°ì—¬ë„ê°€ <em>ì•”ë¬µì ìœ¼ë¡œ</em> SNRì— ì˜ì¡´í•©ë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ:</p>
<div class="formula">$$\mathcal{L}_\epsilon=\mathbb{E}_t\left[\text{SNR}(t)\cdot\|x_\theta-x_0\|^2\right]$$</div>
<p>ë†’ì€ SNR($t\approx 0$, ê±°ì˜ ê¹¨ë—í•œ ì´ë¯¸ì§€)ì—ì„œ ì†ì‹¤ì´ ê³¼ë„í•˜ê²Œ ì»¤ì§€ë©´ ëª¨ë¸ì´ "ì´ë¯¸ ì¶©ë¶„íˆ ê¹¨ë—í•œ ì´ë¯¸ì§€ì˜ ë¯¸ì„¸í•œ ì°¨ì´"ì— ì§‘ì¤‘í•˜ê³ , ì •ì‘ ì¤‘ìš”í•œ êµ¬ì¡°ì  í•™ìŠµ(ë†’ì€ $t$)ì„ ì†Œí™€íˆ í•©ë‹ˆë‹¤. <strong>Min-SNR-Î³</strong>, <strong>debiased estimation</strong> ë“±ì€ ì´ ë¶ˆê· í˜•ì„ ë³´ì •í•©ë‹ˆë‹¤.</p>
</div>

<div class="codebox"># sd-scripts: library/custom_train_functions.py â€” SNR ê³„ì‚°
def compute_snr(timesteps, noise_scheduler):
    alphas_cumprod = noise_scheduler.alphas_cumprod
    sqrt_alphas_cumprod = alphas_cumprod**0.5
    sqrt_one_minus_alphas_cumprod = (1.0 - alphas_cumprod)**0.5
    alpha = sqrt_alphas_cumprod[timesteps]             # signal coeff
    sigma = sqrt_one_minus_alphas_cumprod[timesteps]   # noise coeff
    snr = (alpha / sigma) ** 2                         # SNR(t) = (á¾±/(1-á¾±))
    return snr

# Min-SNR-Î³ ê°€ì¤‘ì¹˜ ì ìš©
snr = compute_snr(timesteps, scheduler)
msnr_weight = torch.clamp(snr, max=gamma) / snr       # min(SNR, Î³) / SNR
loss = loss * msnr_weight                              # ê³ SNR timestep ì–µì œ</div>

<h4>Flow Matchingì—ì„œì˜ SNR í•´ì„</h4>
<p>Flow Matchingì—ì„œëŠ” $\text{signal coeff}=(1-t)$, $\text{noise coeff}=t$ì´ë¯€ë¡œ:</p>
<div class="formula">$$\text{SNR}_\text{FM}(t)=\frac{(1-t)^2}{t^2}=\left(\frac{1-t}{t}\right)^2$$</div>
<p class="small">$t=0$ì—ì„œ $\text{SNR}\to\infty$ (ìˆœìˆ˜ ì‹ í˜¸), $t=1$ì—ì„œ $\text{SNR}\to 0$ (ìˆœìˆ˜ ë…¸ì´ì¦ˆ), $t=0.5$ì—ì„œ $\text{SNR}=1$ (ê· í˜•ì ). ì´ ëŒ€ì¹­ì  êµ¬ì¡°ê°€ Flow Matchingì˜ logit-normal ìƒ˜í”Œë§(ì¤‘ì•™ $t\approx 0.5$ ê°•ì¡°)ì˜ ì´ë¡ ì  ë°°ê²½ì…ë‹ˆë‹¤.</p>
</section>

<section id="math-b" class="tab-panel" data-tab-group="math-sub">
<h3>B. í›ˆë ¨ ëª©ì í•¨ìˆ˜ (Training Objectives)</h3>

<div class="box" style="border-left:3px solid var(--accent);margin-bottom:16px">
<h4 style="margin-top:0">ğŸ¯ ëª¨í‹°ë² ì´ì…˜: ELBOì—ì„œ ì‹¤ìš©ì  ì†ì‹¤ê¹Œì§€</h4>
<p><strong>ìˆ˜í•™ì  ì¶œë°œì :</strong> ìƒì„± ëª¨ë¸ì˜ ì´ë¡ ì  ëª©í‘œëŠ” ë°ì´í„°ì˜ ë¡œê·¸ ìš°ë„ $\log p_\theta(x_0)$ë¥¼ ìµœëŒ€í™”í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë³€ë¶„ í•˜í•œ(ELBO)ì„ ì „ê°œí•˜ë©´:</p>
<div class="formula">$$\log p_\theta(x_0)\geq\underbrace{-D_\text{KL}(q(x_T|x_0)\|p(x_T))}_{\text{prior matching (â‰ˆ0)}}+\sum_{t=2}^T\underbrace{-D_\text{KL}(q(x_{t-1}|x_t,x_0)\|p_\theta(x_{t-1}|x_t))}_{\mathcal{L}_{t-1}\text{: denoising matching}}+\underbrace{\log p_\theta(x_0|x_1)}_{\text{reconstruction}}$$</div>
<p>ê° $\mathcal{L}_{t-1}$ì€ ë‘ ê°€ìš°ì‹œì•ˆ ì‚¬ì´ì˜ KL divergenceì´ë¯€ë¡œ <strong>closed-form MSE</strong>ë¡œ í™˜ì›ë©ë‹ˆë‹¤. ì´ê²ƒì´ "ì™œ MSE ì†ì‹¤ë¡œ ë…¸ì´ì¦ˆë¥¼ ì˜ˆì¸¡í•˜ëŠ”ê°€"ì˜ ìˆ˜í•™ì  ê·¼ê±°ì…ë‹ˆë‹¤.</p>
<p><strong>í›ˆë ¨ ê´€ì :</strong> Ho et al. (2020)ì€ ELBOì˜ ê°€ì¤‘ KL ëŒ€ì‹  <em>ë‹¨ìˆœí™”ëœ ëª©ì í•¨ìˆ˜</em> $\|\epsilon_\theta(x_t,t)-\epsilon\|^2$ì´ ì‹¤ì œë¡œ ë” ì¢‹ì€ ìƒ˜í”Œ í’ˆì§ˆì„ ë‚¸ë‹¤ëŠ” ê²ƒì„ ì‹¤í—˜ì ìœ¼ë¡œ ë³´ì˜€ìŠµë‹ˆë‹¤. ì´ "ë‹¨ìˆœ ëª©ì í•¨ìˆ˜"ê°€ í˜„ì¬ ëª¨ë“  ì½”ë“œë² ì´ìŠ¤ì˜ ì¶œë°œì ì…ë‹ˆë‹¤.</p>
</div>

<h4>ì„¸ ê°€ì§€ ì˜ˆì¸¡ ìœ í˜•ê³¼ ê·¸ ë™ë“±ì„±</h4>
<p>ëª¨ë¸ì´ ì˜ˆì¸¡í•˜ëŠ” ëŒ€ìƒì€ Îµ, v, xâ‚€ ê°ê° ë‹¤ë¥´ì§€ë§Œ, ìˆ˜í•™ì ìœ¼ë¡œ <strong>ì„œë¡œ ë³€í™˜ ê°€ëŠ¥</strong>í•©ë‹ˆë‹¤:</p>

<table>
  <thead><tr><th>ì˜ˆì¸¡ ìœ í˜•</th><th>ëª©ì í•¨ìˆ˜</th><th>íƒ€ê²Ÿ</th><th>ëª¨ë¸</th><th>ì½”ë“œ ìœ„ì¹˜</th></tr></thead>
  <tbody>
    <tr>
      <td><strong>Îµ-prediction</strong></td>
      <td>$$\mathcal{L}_\epsilon=\mathbb{E}_{t,x_0,\epsilon}\left[\|\epsilon_\theta(x_t,t)-\epsilon\|^2\right]$$</td>
      <td>$\epsilon$ (noise)</td>
      <td>SD 1.x, SDXL</td>
      <td><code>train_util.py</code></td>
    </tr>
    <tr>
      <td><strong>v-prediction</strong></td>
      <td>$$\mathcal{L}_v=\mathbb{E}_{t,x_0,\epsilon}\left[\|v_\theta(x_t,t)-v_t\|^2\right]$$</td>
      <td>$v_t=\sqrt{\bar\alpha_t}\epsilon-\sqrt{1-\bar\alpha_t}x_0$</td>
      <td>SD 2.x, SDXL</td>
      <td><code>train_util.py</code></td>
    </tr>
    <tr>
      <td><strong>Flow Matching</strong></td>
      <td>$$\mathcal{L}_\text{FM}=\mathbb{E}_{t,x_0,\epsilon}\left[\|v_\theta(x_t,t)-(\epsilon-x_0)\|^2\right]$$</td>
      <td>$\epsilon-x_0$ (velocity)</td>
      <td>Flux, SD3, Wan</td>
      <td>ê° ëª¨ë¸ train íŒŒì¼</td>
    </tr>
  </tbody>
</table>

<div class="box" style="border-left:3px solid #28a745;margin-bottom:16px">
<h4 style="margin-top:0">ë³€í™˜ ê´€ê³„ â€” í•˜ë‚˜ë¥¼ ì•Œë©´ ëª¨ë‘ ì•ˆë‹¤</h4>
<p>$x_t=\sqrt{\bar\alpha_t}\,x_0+\sqrt{1-\bar\alpha_t}\,\epsilon$ì—ì„œ ê° quantityëŠ” ìƒí˜¸ ë³€í™˜ë©ë‹ˆë‹¤:</p>
<div class="formula">$$\epsilon=\frac{x_t-\sqrt{\bar\alpha_t}\,x_0}{\sqrt{1-\bar\alpha_t}},\qquad x_0=\frac{x_t-\sqrt{1-\bar\alpha_t}\,\epsilon}{\sqrt{\bar\alpha_t}}$$</div>
<div class="formula">$$v_t=\sqrt{\bar\alpha_t}\,\epsilon-\sqrt{1-\bar\alpha_t}\,x_0=\frac{\sqrt{\bar\alpha_t}\,x_t - x_0}{\sqrt{1-\bar\alpha_t}}$$</div>
<p><strong>ì‹¤ìš©ì  ì˜ë¯¸:</strong> sd-scriptsì˜ <code>--v_parameterization</code> í”Œë˜ê·¸ í•˜ë‚˜ë¡œ Îµ-prediction â†” v-prediction ì „í™˜. ë‚´ë¶€ì ìœ¼ë¡œ ê°™ì€ UNetì´ ë‹¤ë¥¸ íƒ€ê²Ÿì„ í•™ìŠµí•©ë‹ˆë‹¤.</p>
</div>

<div class="codebox"># sd-scripts: library/train_util.py â€” ì˜ˆì¸¡ ìœ í˜•ì— ë”°ë¥¸ íƒ€ê²Ÿ ê³„ì‚°
if args.v_parameterization:
    # v-prediction: v = âˆšá¾±Â·Îµ âˆ’ âˆš(1âˆ’á¾±)Â·xâ‚€
    target = noise_scheduler.get_velocity(latents, noise, timesteps)
else:
    # Îµ-prediction: target = ì›ë³¸ ë…¸ì´ì¦ˆ
    target = noise

# sd-scripts: flux_train.py â€” Flow Matching velocity
target = noise - latents  # velocity = Îµ âˆ’ xâ‚€ (constant!)

# DiffSynth-Studio: trainers/text_to_image.py
# flow matchingì—ì„œ targetì€ í•­ìƒ noise - latent
loss = F.mse_loss(model_pred, noise - latent, reduction="none")</div>

<h4>ì™œ v-predictionì´ ë“±ì¥í–ˆëŠ”ê°€?</h4>
<div class="box" style="border-left:3px solid #007bff">
<p><strong>ìˆ˜í•™ì  ì´ìœ :</strong> Îµ-predictionì€ $t\to 0$ (ê±°ì˜ ê¹¨ë—)ì—ì„œ "ì´ë¯¸ í•œ ì¼"ì„ ë°˜ë³µí•˜ê³ , $t\to T$ (ìˆœìˆ˜ ë…¸ì´ì¦ˆ)ì—ì„œ ìš”êµ¬í•˜ëŠ” ì˜ˆì¸¡ì´ ê³¼ë„í•©ë‹ˆë‹¤. v-predictionì€ $\sqrt{\bar\alpha_t}$ì™€ $\sqrt{1-\bar\alpha_t}$ì˜ <em>ê°ë„ ë³´ê°„</em>ìœ¼ë¡œ í•´ì„ë˜ì–´, SNR ìŠ¤í™íŠ¸ëŸ¼ ì „ì²´ì—ì„œ <strong>ì†ì‹¤ ìŠ¤ì¼€ì¼ì´ ë” ê· ì¼</strong>í•©ë‹ˆë‹¤:</p>
<div class="formula">$$\mathcal{L}_v \propto \mathbb{E}_t\left[\frac{\text{SNR}(t)}{\text{SNR}(t)+1}\cdot\|x_\theta-x_0\|^2\right]$$</div>
<p class="small">$\text{SNR}(t)/(\text{SNR}(t)+1)$ëŠ” [0,1]ë¡œ ë°”ìš´ë“œë˜ì–´ ìˆì–´, Îµ-predictionì˜ $\text{SNR}(t)$ ê°€ì¤‘ì¹˜ì²˜ëŸ¼ í­ë°œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.</p>
<p><strong>í›ˆë ¨ ê´€ì :</strong> v-predictionì€ <code>--zero_terminal_snr</code>ê³¼ í•¨ê»˜ ì‚¬ìš©í•˜ë©´ ì™„ì „í•œ ê²€ì€ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤. Îµ-predictionì—ì„œëŠ” $t=T$ì—ì„œë„ ì”ì—¬ ì‹ í˜¸ê°€ ë‚¨ì•„ ì™„ì „íˆ ê²€ì€/ë¹ˆ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ì§€ ëª»í•˜ëŠ” ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.</p>
</div>

<h3>ì†ì‹¤ ë³€í˜• â€” ê¸°ë³¸ MSEë¥¼ ê°œì„ í•˜ëŠ” ê¸°ë²•ë“¤</h3>

<div class="box" style="border-left:3px solid #ffc107;margin-bottom:12px">
<p><strong>ì™œ ì†ì‹¤ì„ ë³€í˜•í•˜ëŠ”ê°€?</strong> ë‹¨ìˆœ MSEëŠ” ëª¨ë“  timestepì„ ë™ë“±í•˜ê²Œ ì·¨ê¸‰í•˜ì§€ë§Œ, ì‹¤ì œë¡œ timestepë³„ í•™ìŠµ ë‚œì´ë„ì™€ ì‹œê°ì  ì¤‘ìš”ë„ê°€ ë‹¤ë¦…ë‹ˆë‹¤. ë„ˆë¬´ ì‰¬ìš´ timestep(ì €ë…¸ì´ì¦ˆ)ì— ê³¼ì í•©í•˜ê±°ë‚˜, ì´ìƒì¹˜(outlier) gradientê°€ í•™ìŠµì„ ë¶ˆì•ˆì •í•˜ê²Œ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
</div>

<table>
  <thead><tr><th>ê¸°ë²•</th><th>ìˆ˜ì‹</th><th>ë™ê¸° &amp; íš¨ê³¼</th><th>ì½”ë“œë² ì´ìŠ¤</th></tr></thead>
  <tbody>
    <tr>
      <td><strong>Min-SNR-Î³</strong></td>
      <td>$$w(t)=\frac{\min(\text{SNR}(t),\gamma)}{\text{SNR}(t)}$$</td>
      <td>$\gamma=5$ê°€ ê¸°ë³¸. SNR > Î³ì¸ ì €ë…¸ì´ì¦ˆ êµ¬ê°„ì—ì„œ ê°€ì¤‘ì¹˜ë¥¼ $\gamma/\text{SNR}<1$ë¡œ í´ë¦¬í•‘í•˜ì—¬ "ì´ë¯¸ ì‰¬ìš´ ë¬¸ì œ"ì— ê³¼ë„í•œ ê·¸ë˜ë””ì–¸íŠ¸ê°€ íë¥´ëŠ” ê²ƒì„ ë°©ì§€. <strong>Pareto ìµœì </strong>ì— ê·¼ì ‘í•˜ëŠ” ê°€ì¤‘ì¹˜ì„ì´ ì´ë¡ ì ìœ¼ë¡œ ì¦ëª…ë¨ (Hang et al., 2023).</td>
      <td><span class="tag sdscripts">sd-scripts</span><span class="tag diffpipe">diffusion-pipe</span></td>
    </tr>
    <tr>
      <td><strong>Debiased Estimation</strong></td>
      <td>$$w_\epsilon(t)=\frac{1}{\sqrt{\text{SNR}(t)}}$$$$w_v(t)=\frac{1}{\text{SNR}(t)+1}$$</td>
      <td>ë‹¨ìˆœ Îµ-prediction MSEëŠ” $x_0$ ë³µì› ê´€ì ì—ì„œ SNRì— ë¹„ë¡€í•˜ëŠ” <em>í¸í–¥(bias)</em>ì„ ê°€ì§€ê³  ìˆìŒ. ì´ ê°€ì¤‘ì¹˜ë¡œ í¸í–¥ì„ ì œê±°í•˜ë©´ ëª¨ë“  timestepì—ì„œ $x_0$ ë³µì› ëŠ¥ë ¥ì´ ê· ë“±í•´ì§.</td>
      <td><span class="tag sdscripts">sd-scripts</span><span class="tag diffpipe">diffusion-pipe</span></td>
    </tr>
    <tr>
      <td><strong>Pseudo-Huber</strong></td>
      <td>$$\mathcal{L}_\text{Huber}=\sqrt{(x-y)^2+c^2}-c$$</td>
      <td>$c\to 0$ì´ë©´ L1(ì¤‘ê°„ê°’), $c\to\infty$ì´ë©´ L2(í‰ê· ê°’)ìœ¼ë¡œ ìˆ˜ë ´. ì´ìƒì¹˜(outlier) ë°ì´í„°ì—ì„œ gradientê°€ í­ë°œí•˜ëŠ” ê²ƒì„ ë°©ì§€. ì •ë°€ ë””í…Œì¼ë³´ë‹¤ ì „ì²´ì  ì¼ê´€ì„±ì´ ì¤‘ìš”í•œ í•™ìŠµ ì´ˆë°˜ì— ìœ ë¦¬.</td>
      <td><span class="tag sdscripts">sd-scripts</span><span class="tag diffpipe">diffusion-pipe</span></td>
    </tr>
    <tr>
      <td><strong>Bell-shaped ê°€ì¤‘ì¹˜</strong></td>
      <td>$$w(t)=\exp\!\left(-2\left(\frac{t-\mu}{\sigma}\right)^2\right)$$</td>
      <td>DiffSynthì˜ ê²½í—˜ì  ë°œê²¬: ì¤‘ê°„ timestep($t\approx 500/1000$)ì´ êµ¬ì¡°ì™€ ë””í…Œì¼ì˜ "êµì°¨ì "ì´ë¯€ë¡œ, ê°€ìš°ì‹œì•ˆ í˜•íƒœë¡œ ì¤‘ì•™ë¶€ë¥¼ ê°•ì¡°í•˜ë©´ ì „ì²´ì  í’ˆì§ˆì´ í–¥ìƒí•©ë‹ˆë‹¤.</td>
      <td><span class="tag diffsynth">DiffSynth</span></td>
    </tr>
    <tr>
      <td><strong>Masked Loss</strong></td>
      <td>$$\mathcal{L}=\frac{\sum_{i,j}m_{ij}\cdot\ell_{ij}}{\sum_{i,j}m_{ij}}$$</td>
      <td>íŠ¹ì • í”¼ì‚¬ì²´/ì˜ì—­ë§Œ í•™ìŠµí•˜ê³  ë°°ê²½ì€ ë¬´ì‹œ. $m_{ij}\in\{0,1\}$ëŠ” ê³µê°„ ë§ˆìŠ¤í¬. ìºë¦­í„° LoRA í•™ìŠµì—ì„œ ë°°ê²½ ê³¼ì í•©ì„ ë°©ì§€í•˜ëŠ” í•µì‹¬ ë„êµ¬.</td>
      <td><span class="tag sdscripts">sd-scripts</span><span class="tag diffpipe">diffusion-pipe</span></td>
    </tr>
  </tbody>
</table>

<div class="codebox"># sd-scripts: library/custom_train_functions.py â€” Min-SNR-Î³ êµ¬í˜„
def apply_snr_weight(loss, timesteps, noise_scheduler, gamma, v_prediction):
    snr = compute_snr(timesteps, noise_scheduler)       # SNR(t)
    if v_prediction:
        snr += 1  # v-prediction: SNR ë³´ì • (SNR+1 ê°€ì¤‘ì¹˜)
    # clamp & normalize
    msnr = torch.clamp(snr, max=gamma)                  # min(SNR, Î³)
    weight = msnr / snr                                  # â†’ 1.0 if SNRâ‰¤Î³, else Î³/SNR < 1
    loss = loss * weight                                 # timestepë³„ ì¬ê°€ì¤‘
    return loss

# Pseudo-Huber (sd-scripts)
if loss_type == "huber":
    loss = torch.sqrt((pred - target)**2 + huber_c**2) - huber_c
elif loss_type == "smooth_l1":
    loss = F.smooth_l1_loss(pred, target, reduction="none")
else:  # default L2
    loss = F.mse_loss(pred, target, reduction="none")

# DiffSynth: diffsynth/trainers/text_to_image.py â€” Bell-shaped weight
# weight = torch.exp(-2 * ((timestep - 500) / 1000) ** 2)
# loss = loss * weight.view(-1, 1, 1, 1)</div>
</section>

<section id="math-c" class="tab-panel" data-tab-group="math-sub">
<h3>C. Flow Matching â€” Timestep ìƒ˜í”Œë§ê³¼ ê°€ì¤‘ì¹˜ ì „ëµ</h3>

<div class="box" style="border-left:3px solid var(--accent);margin-bottom:16px">
<h4 style="margin-top:0">ğŸ¯ ëª¨í‹°ë² ì´ì…˜: ì™œ timestep ë¶„í¬ê°€ ì¤‘ìš”í•œê°€?</h4>
<p><strong>ìˆ˜í•™ì  ê´€ì :</strong> Flow Matchingì˜ í›ˆë ¨ ëª©ì í•¨ìˆ˜ $\mathcal{L}=\mathbb{E}_{t\sim p(t)}[w(t)\|v_\theta-v_\text{target}\|^2]$ì—ì„œ, $t$ì˜ ìƒ˜í”Œë§ ë¶„í¬ $p(t)$ëŠ” <em>ì•”ë¬µì  ê°€ì¤‘ì¹˜(implicit weighting)</em>ë¡œ ì‘ìš©í•©ë‹ˆë‹¤. ê· ì¼ ë¶„í¬ $p(t)=U[0,1]$ì„ ì‚¬ìš©í•˜ë©´ ëª¨ë“  ë…¸ì´ì¦ˆ ìˆ˜ì¤€ì— ë™ë“±í•œ í•™ìŠµ ì˜ˆì‚°ì„ ë°°ë¶„í•˜ì§€ë§Œ, ì‹¤ì œë¡œëŠ” íŠ¹ì • $t$ êµ¬ê°„ì´ ìƒì„± í’ˆì§ˆì— ë¶ˆê· ë“±í•˜ê²Œ ê¸°ì—¬í•©ë‹ˆë‹¤.</p>
<p><strong>í›ˆë ¨ ê´€ì :</strong> $t\approx 0$ (ê±°ì˜ ê¹¨ë—í•œ ì´ë¯¸ì§€)ì—ì„œì˜ velocity ì˜ˆì¸¡ì€ "ê±°ì˜ 0ì— ê°€ê¹Œìš´ ê°’ì„ ì˜ˆì¸¡"í•˜ëŠ” ì‰¬ìš´ ê³¼ì œì´ê³ , $t\approx 1$ (ìˆœìˆ˜ ë…¸ì´ì¦ˆ)ì—ì„œëŠ” "ì „ì²´ ì´ë¯¸ì§€ë¥¼ í•œ ë²ˆì— ì˜ˆì¸¡"í•´ì•¼ í•˜ëŠ” ê·¹ë„ë¡œ ì–´ë ¤ìš´ ê³¼ì œì…ë‹ˆë‹¤. ì¤‘ê°„ ì˜ì—­($t\approx 0.3\sim 0.7$)ì´ êµ¬ì¡°ì™€ ì„¸ë¶€ ì‚¬í•­ì˜ ê· í˜•ì ìœ¼ë¡œ, ì—¬ê¸°ì— í•™ìŠµ ì˜ˆì‚°ì„ ì§‘ì¤‘í•˜ë©´ íš¨ìœ¨ì´ ê·¹ëŒ€í™”ë©ë‹ˆë‹¤.</p>
</div>

<h4>Timestep ìƒ˜í”Œë§ ë¶„í¬ ìƒì„¸ ë¹„êµ</h4>
<table>
  <thead><tr><th>ì „ëµ</th><th>ìˆ˜ì‹</th><th>ì½”ë“œ í”Œë˜ê·¸</th><th>ì§ê´€ &amp; ì‚¬ìš© ì‚¬ë¡€</th></tr></thead>
  <tbody>
    <tr>
      <td><strong>Uniform</strong></td>
      <td>$$t\sim U[0,1]$$</td>
      <td><code>timestep_sampling=uniform</code></td>
      <td>ê°€ì¥ ë‹¨ìˆœ. í¸í–¥ ì—†ì§€ë§Œ ì–‘ ê·¹ë‹¨ì—ì„œ í•™ìŠµ íš¨ìœ¨ ë‚­ë¹„. ë² ì´ìŠ¤ë¼ì¸ìš©.</td>
    </tr>
    <tr>
      <td><strong>Logit-Normal</strong></td>
      <td>$$t=\sigma(\mu+s\cdot z),\;z\sim\mathcal{N}(0,1)$$<br>$$p(t)\propto\frac{1}{t(1-t)}\exp\!\left(-\frac{(\text{logit}(t)-\mu)^2}{2s^2}\right)$$</td>
      <td><code>weighting_scheme=logit_normal</code></td>
      <td>SD3 ë…¼ë¬¸ì˜ í•µì‹¬ ê¸°ì—¬. $\mu=0,s=1$ì´ë©´ ì¤‘ì•™($t\approx0.5$) ì§‘ì¤‘. $\text{logit}(t)=\ln(t/(1-t))$ë¥¼ ì •ê·œ ë¶„í¬ë¡œ ë§Œë“¤ì–´ ì–‘ ê·¹ë‹¨ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì–µì œ.</td>
    </tr>
    <tr>
      <td><strong>Sigmoid</strong></td>
      <td>$$t=\sigma(s\cdot z),\;z\sim\mathcal{N}(0,1)$$</td>
      <td><code>timestep_sampling=sigmoid</code></td>
      <td>Logit-Normalì˜ $\mu=0$ íŠ¹ìˆ˜ ê²½ìš°. Flux ê¸°ë³¸ ì„¤ì •. $s$ê°€ í´ìˆ˜ë¡ ë” ë„“ê²Œ í¼ì§.</td>
    </tr>
    <tr>
      <td><strong>Mode</strong></td>
      <td>$$t=1-u-s\cdot(\cos^2(\pi u/2)-1+u)$$<br>$$u\sim U[0,1]$$</td>
      <td><code>weighting_scheme=mode</code></td>
      <td>ì½”ì‚¬ì¸ ë³€í™˜ìœ¼ë¡œ logit-normalì˜ <em>ìµœë¹ˆê°’(mode)</em> ì£¼ë³€ì— ì§‘ì¤‘. logit-normalë³´ë‹¤ ë” sharpí•œ í”¼í¬.</td>
    </tr>
    <tr>
      <td><strong>CosMap</strong></td>
      <td>$$t=1-\frac{1}{\tan(\pi u/2)+1}$$<br>$$u\sim U[0,1]$$</td>
      <td><code>weighting_scheme=cosmap</code></td>
      <td>íƒ„ì  íŠ¸ ë³€í™˜ìœ¼ë¡œ ì½”ì‚¬ì¸ ìŠ¤ì¼€ì¤„ì„ Flow Matchingì— ì´ì‹. ì½”ì‚¬ì¸ noise scheduleì˜ "ê· ë“± SNR ë³€í™”ìœ¨" íš¨ê³¼ë¥¼ ì¬í˜„.</td>
    </tr>
    <tr>
      <td><strong>Flux Shift</strong></td>
      <td>$$\mu=0.5+\frac{H\times W}{256^2}\cdot 1.15$$<br>$$t=\sigma(\mu+s\cdot z)$$</td>
      <td><code>timestep_sampling=flux_shift</code></td>
      <td><strong>í•´ìƒë„ ì ì‘í˜•.</strong> í° ì´ë¯¸ì§€ëŠ” ë” ë§ì€ ë…¸ì´ì¦ˆë¥¼ í•„ìš”ë¡œ í•˜ë¯€ë¡œ(content ë°€ë„ â†‘), $\mu$ë¥¼ í‚¤ì›Œ ë†’ì€ $t$ ìª½ì„ ë” ìƒ˜í”Œ. Fluxì˜ í•µì‹¬ ì„¤ê³„.</td>
    </tr>
    <tr>
      <td><strong>Sigma-sqrt</strong></td>
      <td>$$w(\sigma)=\sigma^{-2}$$</td>
      <td><code>weighting_scheme=sigma_sqrt</code></td>
      <td>EDM-style ê°€ì¤‘ì¹˜. ë‚®ì€ $\sigma$(ê³ SNR)ì—ì„œ ê°€ì¤‘ì¹˜ ì¦ê°€. ì„¸ë°€í•œ ë””í…Œì¼ í•™ìŠµ ê°•ì¡°.</td>
    </tr>
  </tbody>
</table>

<h4>ìˆ˜í•™ì  í†µí•©: ìƒ˜í”Œë§ ë¶„í¬ â†” ì†ì‹¤ ê°€ì¤‘ì¹˜ = ë™ì¼ íš¨ê³¼</h4>
<div class="box" style="border-left:3px solid #28a745;margin-bottom:12px">
<p><strong>í•µì‹¬ ì •ë¦¬:</strong> timestep ìƒ˜í”Œë§ ë¶„í¬ë¥¼ ë°”ê¾¸ëŠ” ê²ƒê³¼ ì†ì‹¤ ê°€ì¤‘ì¹˜ë¥¼ ë°”ê¾¸ëŠ” ê²ƒì€ ìˆ˜í•™ì ìœ¼ë¡œ ë™ì¹˜ì…ë‹ˆë‹¤:</p>
<div class="formula">$$\mathbb{E}_{t\sim p(t)}\left[\|v_\theta-v\|^2\right]=\mathbb{E}_{t\sim U[0,1]}\left[\frac{p(t)}{1}\cdot\|v_\theta-v\|^2\right]=\mathbb{E}_{t\sim U[0,1]}\left[w(t)\cdot\|v_\theta-v\|^2\right]$$</div>
<p>ì¦‰, logit-normal ë¶„í¬ì—ì„œ $t$ë¥¼ ìƒ˜í”Œí•˜ëŠ” ê²ƒê³¼, uniformì—ì„œ ìƒ˜í”Œí•œ ë’¤ logit-normal ë°€ë„ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ê³±í•˜ëŠ” ê²ƒì€ <em>ë™ì¼í•œ gradient ê¸°ëŒ€ê°’</em>ì„ ì¤ë‹ˆë‹¤. ì‹¤ì „ì—ì„œëŠ” sampling ë°©ì‹ì´ varianceê°€ ë” ë‚®ì•„ ì„ í˜¸ë©ë‹ˆë‹¤.</p>
</div>

<div class="codebox"># sd-scripts: library/flux_train_utils.py â€” Timestep ìƒ˜í”Œë§ êµ¬í˜„
def get_timesteps(args, batch_size, device):
    if args.timestep_sampling == "uniform":
        t = torch.rand(batch_size, device=device)
    
    elif args.timestep_sampling == "sigmoid":
        # Sigmoid: t = Ïƒ(sÂ·z), z ~ N(0,1)
        t = torch.sigmoid(args.sigmoid_scale * torch.randn(batch_size, device=device))
    
    elif args.timestep_sampling == "flux_shift":
        # í•´ìƒë„ ì ì‘: Î¼ = 0.5 + (HÃ—W/256Â²)Â·1.15
        mu = 0.5 + (height * width / 256**2) * 1.15
        t = torch.sigmoid(mu + args.sigmoid_scale * torch.randn(batch_size, device=device))
    
    elif args.timestep_sampling == "logit_normal":
        # logit(t) ~ N(Î¼, sÂ²) â†’ t = Ïƒ(Î¼ + sÂ·z)
        t = torch.sigmoid(args.logit_mean + args.logit_std * torch.randn(batch_size, device=device))
    
    return t

# diffusion-pipe: ëª¨ë¸ë³„ ë‚´ë¶€ êµ¬í˜„ì´ ë‹¤ë¥´ë‚˜ ì›ë¦¬ ë™ì¼
# DiffSynth-Studio: FlowMatchScheduler ë‚´ì—ì„œ bell-shaped ë¶„í¬ ì‚¬ìš©</div>

<h4>Discrete Flow Shift â€” ì¶”ë¡ ìš© $\sigma$ ë³€í™˜ê³¼ í›ˆë ¨ì˜ ê´€ê³„</h4>
<div class="formula">$$\sigma'=\frac{s\cdot\sigma}{1+(s-1)\sigma},\qquad s=\text{discrete\_flow\_shift}$$</div>
<p><strong>ìˆ˜í•™ì  ì˜ë¯¸:</strong> ì´ ë¹„ì„ í˜• ë³€í™˜ì€ $\sigma\in[0,1]$ì„ ì¬ë¶„ë°°í•©ë‹ˆë‹¤. $s>1$ì´ë©´ ê³ ë…¸ì´ì¦ˆ ë°©í–¥ìœ¼ë¡œ ìŠ¤ì¼€ì¤„ì´ ì‹œí”„íŠ¸ë˜ê³  $s<1$ì´ë©´ ì €ë…¸ì´ì¦ˆ ë°©í–¥. <strong>í›ˆë ¨ ì‹œ ì´ shiftë¥¼ ë°˜ì˜</strong>í•´ì•¼ ì¶”ë¡ ê³¼ ì¼ê´€ì„±ì´ ìœ ì§€ë©ë‹ˆë‹¤.</p>
<div class="codebox"># sd-scripts: ì¶”ë¡  ì‹œ sigma shift ì ìš© (í•™ìŠµ ì‹œì—ë„ ì ìš© ê°€ëŠ¥)
# --discrete_flow_shift=3.0 (Flux dev ê¸°ë³¸), 1.0 (schnell)
sigmas_shifted = shift * sigmas / (1 + (shift - 1) * sigmas)
# ì§ê´€: shift=3ì´ë©´ ë‚®ì€ sigmaê°€ ë” ë†’ì€ ê°’ìœ¼ë¡œ ë°€ë ¤ë‚¨ â†’ ë” ë§ì€ denoising ìŠ¤í…</div>

<div class="formula">
$$\boxed{\text{ì¼ë°˜ Flow Matching ì†ì‹¤: }\quad\mathcal{L}=\mathbb{E}_{t\sim p(t)}\left[w(t)\|v_\theta(x_t,t,c)-(\epsilon-x_0)\|^2\right]}$$
</div>
</section>

<section id="math-d" class="tab-panel" data-tab-group="math-sub">
<h3>D. ìµœì í™” ì´ë¡  â€” Optimizerì˜ ìˆ˜í•™ê³¼ í™•ì‚° í›ˆë ¨ì—ì„œì˜ ì˜ë¯¸</h3>

<div class="box" style="border-left:3px solid var(--accent);margin-bottom:16px">
<h4 style="margin-top:0">ğŸ¯ ëª¨í‹°ë² ì´ì…˜: ì™œ ì˜µí‹°ë§ˆì´ì € ì„ íƒì´ ì¤‘ìš”í•œê°€?</h4>
<p><strong>ìˆ˜í•™ì  ê´€ì :</strong> í™•ì‚° ëª¨ë¸ì˜ ì†ì‹¤ í•¨ìˆ˜ $\mathcal{L}(\theta)$ëŠ” ë¹„ë³¼ë¡(non-convex)ì´ë©° ìˆ˜ì–µ~ìˆ˜ì‹­ì–µ ì°¨ì›ì˜ íŒŒë¼ë¯¸í„° ê³µê°„ì—ì„œ ì •ì˜ë©ë‹ˆë‹¤. SGDëŠ” ì´ëŸ° ê³ ì°¨ì› ë¹„ë³¼ë¡ ìµœì í™”ì—ì„œ <em>ì•ˆì¥ì (saddle point)</em>ì— ê°‡íˆê¸° ì‰½ê³ , ì°¨ì›ë³„ ê³¡ë¥ (curvature)ì´ í¬ê²Œ ë‹¤ë¥¸ <strong>ill-conditioned</strong> ë¬¸ì œì—ì„œ ìˆ˜ë ´ì´ ëŠë¦½ë‹ˆë‹¤.</p>
<p><strong>í›ˆë ¨ ê´€ì :</strong> í™•ì‚° ëª¨ë¸ì€ ë°ì´í„°ì…‹ì´ í¬ê³  í•™ìŠµë¥ ì— ë¯¼ê°í•©ë‹ˆë‹¤. AdamWì˜ ì ì‘ì  í•™ìŠµë¥ ì€ ë ˆì´ì–´ë³„ë¡œ ìë™ ìŠ¤ì¼€ì¼ë§í•˜ì—¬ ì´ë¥¼ ì™„í™”í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ 12B+ íŒŒë¼ë¯¸í„° ëª¨ë¸ì—ì„œ AdamWì˜ 8N ë°”ì´íŠ¸ ìƒíƒœ ë©”ëª¨ë¦¬(m, v ê°ê° FP32)ëŠ” VRAMì˜ ì£¼ìš” ë³‘ëª©ì´ ë˜ì–´, 8-bit ì–‘ìí™”, ìƒíƒœ ë¶„í•´(Adafactor), ìƒíƒœ ì—†ëŠ” ì˜µí‹°ë§ˆì´ì €(Lion) ë“±ì´ í•„ìš”í•©ë‹ˆë‹¤.</p>
</div>

<h4>SGD + Momentum â€” ê¸°ì´ˆì™€ í•œê³„</h4>
<div class="grid2">
  <div class="box">
    <h4>Vanilla SGD</h4>
    <div class="formula">$$\theta_{t+1}=\theta_t-\eta\,g_t,\qquad g_t=\nabla_\theta\mathcal{L}(\theta_t)$$</div>
    <p class="small"><strong>ë¬¸ì œ:</strong> ê³¡ë¥ ì´ í° ë°©í–¥(ê°€íŒŒë¥¸ ê³¨ì§œê¸°)ì—ì„œ ì§„ë™í•˜ê³ , í‰í‰í•œ ë°©í–¥ì—ì„œëŠ” ëŠë¦¬ê²Œ ì´ë™. í™•ì‚° ëª¨ë¸ì—ì„œ ë‹¨ë… ì‚¬ìš©ì€ ê±°ì˜ ì—†ìŒ.</p>
  </div>
  <div class="box">
    <h4>+ Momentum (Heavy Ball)</h4>
    <div class="formula">$$m_t=\beta m_{t-1}+g_t$$</div>
    <div class="formula">$$\theta_{t+1}=\theta_t-\eta\,m_t$$</div>
    <p class="small">$\beta=0.9$: ê³¼ê±° 10ìŠ¤í…ì˜ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ì§€ìˆ˜ í‰ê· . ì§„ë™ ì–µì œ + í‰í‰í•œ ë°©í–¥ ê°€ì†. Nesterov ë³€í˜•: $g_t=\nabla_\theta\mathcal{L}(\theta_t-\eta\beta m_{t-1})$ ("ë¨¼ì € ì í”„ í›„ ë³´ì •")</p>
  </div>
</div>

<div class="codebox"># diffusion-pipe: GenericOptim ì—ì„œ SGDëŠ” Muonì˜ fallbackìœ¼ë¡œ ì‚¬ìš©
# 1D/bias í…ì„œì— AdamW, 2D+ í…ì„œì— Muon ì ìš©
# sd-scripts: --optimizer_type=SGDNesterov --optimizer_args momentum=0.9</div>

<h4>AdamW â€” í™•ì‚° í›ˆë ¨ì˜ í‘œì¤€</h4>
<div class="box" style="border-left:3px solid #28a745;margin-bottom:12px">
<p><strong>ì™œ Adam ê³„ì—´ì´ í‘œì¤€ì¸ê°€?</strong></p>
<p>1) <strong>ì ì‘ì  í•™ìŠµë¥ :</strong> $1/\sqrt{\hat v_t}$ì´ ê° íŒŒë¼ë¯¸í„°ì˜ "í‰ê·  ê·¸ë˜ë””ì–¸íŠ¸ í¬ê¸°"ì˜ ì—­ìˆ˜ ì—­í• ì„ í•˜ì—¬, í° ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ë°›ëŠ” íŒŒë¼ë¯¸í„°ëŠ” ì‘ê²Œ, ì‘ì€ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ë°›ëŠ” íŒŒë¼ë¯¸í„°ëŠ” í¬ê²Œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤. UNet/DiTì˜ ì„œë¡œ ë‹¤ë¥¸ ë ˆì´ì–´ì—ì„œ ìì—°ìŠ¤ëŸ¬ìš´ í•™ìŠµë¥  ì ì‘ì´ ì¼ì–´ë‚©ë‹ˆë‹¤.</p>
<p>2) <strong>ë¶„ì‚° í™˜ê²½ ì•ˆì •ì„±:</strong> EMA ê¸°ë°˜ í†µê³„ê°€ ë¯¸ë‹ˆë°°ì¹˜ ë…¸ì´ì¦ˆë¥¼ í‰í™œí™”í•˜ì—¬ ë¶„ì‚° í•™ìŠµ(multi-GPU)ì—ì„œë„ ì•ˆì •ì ì…ë‹ˆë‹¤.</p>
</div>

<div class="formula">$$\text{1ì°¨ ëª¨ë©˜íŠ¸ (í‰ê· ): } m_t=\beta_1 m_{t-1}+(1-\beta_1)g_t$$</div>
<div class="formula">$$\text{2ì°¨ ëª¨ë©˜íŠ¸ (ë¶„ì‚°): } v_t=\beta_2 v_{t-1}+(1-\beta_2)g_t^2$$</div>
<div class="formula">$$\text{í¸í–¥ ë³´ì •: } \hat m_t=\frac{m_t}{1-\beta_1^t},\quad \hat v_t=\frac{v_t}{1-\beta_2^t}$$</div>
<div class="formula">$$\boxed{\theta_{t+1}=\theta_t-\eta\left(\frac{\hat m_t}{\sqrt{\hat v_t}+\epsilon}+\lambda\theta_t\right)}$$</div>

<p><strong>AdamW vs Adam+L2:</strong> ì›ë˜ Adamì—ì„œ $\lambda\|theta\|^2$ë¥¼ ì†ì‹¤ì— ì¶”ê°€í•˜ë©´ ì ì‘ì  í•™ìŠµë¥ ê³¼ ìƒí˜¸ì‘ìš©í•˜ì—¬ weight decay íš¨ê³¼ê°€ ì™œê³¡ë©ë‹ˆë‹¤. AdamWëŠ” $\lambda\theta_t$ë¥¼ <strong>ê·¸ë˜ë””ì–¸íŠ¸ ìŠ¤í…ê³¼ ë…ë¦½ì ìœ¼ë¡œ</strong> ë¹¼ì„œ ì´ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.</p>

<div class="codebox"># ëª¨ë“  ì½”ë“œë² ì´ìŠ¤ì˜ ê¸°ë³¸ ì˜µí‹°ë§ˆì´ì €
# sd-scripts: library/train_util.py
optimizer = torch.optim.AdamW(
    params, lr=args.learning_rate,
    betas=(args.adam_beta1, args.adam_beta2),  # (0.9, 0.999) default
    weight_decay=args.adam_weight_decay,        # 0.01 default
    eps=args.adam_epsilon                       # 1e-8 default
)
# ë©”ëª¨ë¦¬: íŒŒë¼ë¯¸í„° Nê°œ â†’ m(FP32)=4N + v(FP32)=4N = 8N bytes ì¶”ê°€

# diffusion-pipe: configs/*.toml
[optimizer]
type = "adamw"
lr = 1e-4
betas = [0.9, 0.999]
weight_decay = 0.01

# DiffSynth-Studio: torch.optim.AdamW ì§ì ‘ ì‚¬ìš©
optimizer = torch.optim.AdamW(trainable_params, lr=1e-4, weight_decay=1e-2)</div>

<h4>Lion â€” ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ëŒ€ì•ˆ</h4>
<div class="grid2">
  <div class="box">
    <div class="formula">$$u_t=\text{sign}\!\left(\beta_1 m_{t-1}+(1-\beta_1)g_t\right)$$</div>
    <div class="formula">$$\theta_{t+1}=\theta_t-\eta(u_t+\lambda\theta_t)$$</div>
    <div class="formula">$$m_t=\beta_2 m_{t-1}+(1-\beta_2)g_t$$</div>
  </div>
  <div class="box">
    <p><strong>ìˆ˜í•™ì  í•µì‹¬:</strong> ì—…ë°ì´íŠ¸ê°€ $\text{sign}(\cdot)\in\{-1,+1\}$ì´ë¯€ë¡œ ëª¨ë“  íŒŒë¼ë¯¸í„°ê°€ <em>ë™ì¼í•œ í¬ê¸°</em>ë¡œ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤. $v_t$ ìƒíƒœê°€ ì—†ì–´ ë©”ëª¨ë¦¬ 4N (vs AdamW 8N).</p>
    <p><strong>í›ˆë ¨ ê´€ì :</strong> Lionì€ lrì„ AdamWì˜ 3~10ë°° ì‘ê²Œ (ì˜ˆ: 1e-5 â†’ 3e-6), weight_decayë¥¼ 3~10ë°° í¬ê²Œ (ì˜ˆ: 0.01 â†’ 0.1) ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤. ë¶€í˜¸ ê¸°ë°˜ì´ë¼ ê·¸ë˜ë””ì–¸íŠ¸ í¬ê¸° ì •ë³´ë¥¼ ë²„ë¦¬ë¯€ë¡œ <em>ì‘ì€ ë°ì´í„°ì…‹ì—ì„œ ê³¼ì í•© ìœ„í—˜</em>.</p>
    <p class="small"><code>sd-scripts: --optimizer_type=Lion</code></p>
  </div>
</div>

<h4>Adafactor â€” ëŒ€í˜• ëª¨ë¸ì„ ìœ„í•œ í–‰ë ¬ ë¶„í•´</h4>
<div class="box" style="border-left:3px solid #007bff;margin-bottom:12px">
<p><strong>ìˆ˜í•™ì  íŠ¸ë¦­:</strong> Adamì˜ $v_t\in\mathbb{R}^{m\times n}$ ëŒ€ì‹ , í–‰/ì—´ í†µê³„ $v^{(r)}\in\mathbb{R}^m$, $v^{(c)}\in\mathbb{R}^n$ë§Œ ì €ì¥í•˜ì—¬ <strong>ì™¸ì ìœ¼ë¡œ ê·¼ì‚¬</strong>í•©ë‹ˆë‹¤:</p>
<div class="formula">$$v_t^{(r)}=\rho\cdot v_{t-1}^{(r)}+(1-\rho)\cdot\text{RowMean}(g_t^2)$$</div>
<div class="formula">$$v_t^{(c)}=\rho\cdot v_{t-1}^{(c)}+(1-\rho)\cdot\text{ColMean}(g_t^2)$$</div>
<div class="formula">$$\hat v_t\approx\frac{v_t^{(r)}\otimes v_t^{(c)}}{\text{mean}(v_t^{(c)})}$$</div>
<p><strong>ë©”ëª¨ë¦¬ ì ˆê°:</strong> $m\times n$ í–‰ë ¬ì—ì„œ $m+n$ ë²¡í„°ë¡œ ì¶•ì†Œ. 1024Ã—1024 í–‰ë ¬ì´ë©´ $\frac{2048}{1048576}\approx 0.2\%$ì˜ ë©”ëª¨ë¦¬ë§Œ ì‚¬ìš©.</p>
<p><strong>í›ˆë ¨ ê´€ì :</strong> sd-scriptsì—ì„œ <code>--fused_backward_pass</code>ì™€ í•¨ê»˜ ì‚¬ìš©í•˜ë©´ backwardì™€ optimizer stepì„ ë ˆì´ì–´ë³„ë¡œ ìœµí•©í•˜ì—¬ peak VRAMì„ ì¶”ê°€ ì ˆê°í•©ë‹ˆë‹¤. ëŒ€í˜• ëª¨ë¸(SDXL full-finetune)ì—ì„œ ì‚¬ì‹¤ìƒ ìœ ì¼í•œ ì„ íƒì§€.</p>
</div>

<div class="codebox"># sd-scriptsì—ì„œ Adafactor ì‚¬ìš© (fused backward pass)
# --optimizer_type=Adafactor --fused_backward_pass
# peak VRAM: AdamW ëŒ€ë¹„ ì•½ 60-70% ìˆ˜ì¤€

# í•µì‹¬: scale_parameter=Trueë©´ ìì²´ í•™ìŠµë¥  ê³„ì‚°
# relative_step=False + ì™¸ë¶€ lr_scheduler ì‚¬ìš© ê¶Œì¥</div>

<h4>Prodigy â€” í•™ìŠµë¥  ìë™ ì¶”ì •</h4>
<div class="box" style="border-left:3px solid #ffc107;margin-bottom:12px">
<p><strong>ìˆ˜í•™ì  ì›ë¦¬ (D-Adaptation):</strong> ìµœì  í•™ìŠµë¥  $d^*$ì˜ í•˜í•œì„ ì˜¨ë¼ì¸ìœ¼ë¡œ ì¶”ì •í•©ë‹ˆë‹¤. í•µì‹¬ í†µì°°: "ê·¸ë˜ë””ì–¸íŠ¸ì™€ ëˆ„ì  ì—…ë°ì´íŠ¸ì˜ ë‚´ì "ì´ ìµœì  $d^*$ì— ë¹„ë¡€í•œë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.</p>
<div class="formula">$$d_t=\max\!\left(d_{t-1},\;\frac{\sum_{s=1}^t\langle g_s,\,x_s-x_0\rangle}{\sqrt{\sum_{s=1}^t\|g_s\|^2}}\right)$$</div>
<div class="formula">$$\text{effective LR}=d_t\cdot\eta_\text{lr}\qquad(\eta_\text{lr}\approx 1.0\text{ ê¶Œì¥})$$</div>
<p><strong>í›ˆë ¨ ê´€ì :</strong> LoRA í•™ìŠµì—ì„œ "í•™ìŠµë¥ ì„ ì–¼ë§ˆë¡œ ì¡ì„ê¹Œ?"ë¼ëŠ” ê°€ì¥ í”í•œ ì§ˆë¬¸ì„ ì—†ì•±ë‹ˆë‹¤. ëŒ€ì‹  <code>d_coef</code>(ë³´ìˆ˜ì„±)ì™€ <code>growth_rate</code>(ìµœëŒ€ ì¦ê°€ ì†ë„)ë¡œ ê°„ì ‘ ì œì–´. ì´ˆë°˜ ëª‡ ë°± ìŠ¤í…ì€ $d_t$ê°€ ìˆ˜ë ´ ì¤‘ì´ë¯€ë¡œ ì›Œë°ì—… ê¸°ê°„ìœ¼ë¡œ ê°„ì£¼.</p>
</div>

<div class="codebox"># sd-scripts: --optimizer_type=Prodigy --learning_rate=1.0
# í•µì‹¬: lr=1.0ìœ¼ë¡œ ì„¤ì •! (Prodigyê°€ ë‚´ë¶€ì ìœ¼ë¡œ d_të¥¼ ê³±í•˜ì—¬ ì‹¤íš¨ lr ê³„ì‚°)
optimizer_args = ["d_coef=2.0", "growth_rate=inf", "safeguard_warmup=true"]

# diffusion-pipe: configs/*.toml
[optimizer]
type = "prodigy"
lr = 1.0
d_coef = 2.0

# ëª¨ë‹ˆí„°ë§: d_t ì¶”ì ì´ ì¤‘ìš”
# â†’ wandb/tensorboardì—ì„œ d_t ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ ìˆ˜ë ´ íŒë‹¨</div>

<h4>8-bit Quantized Optimizers â€” ì •ë°€ë„ì™€ ë©”ëª¨ë¦¬ì˜ íŠ¸ë ˆì´ë“œì˜¤í”„</h4>
<div class="grid2">
  <div class="box">
    <h4>Dynamic Quantization</h4>
    <div class="formula">$$m_t^{(8)}=Q_8(m_t)=\text{round}\!\left(\frac{m_t}{\max_\text{block}|m_t|}\cdot 127\right)$$</div>
    <div class="formula">$$v_t^{(8)}=Q_8(v_t)\quad\text{(ë™ì¼ ë°©ì‹)}$$</div>
    <p class="small"><strong>ë™ì‘:</strong> í…ì„œë¥¼ 64~2048 í¬ê¸°ì˜ ë¸”ë¡ìœ¼ë¡œ ë‚˜ëˆ„ê³ , ê° ë¸”ë¡ì˜ absmaxë¡œ ìŠ¤ì¼€ì¼ë§ í›„ INT8ë¡œ ì–‘ìí™”. ë§¤ ìŠ¤í…ë§ˆë‹¤ ì—­ì–‘ìí™” â†’ ì—°ì‚° â†’ ì¬ì–‘ìí™”.</p>
    <p class="small"><strong>VRAM:</strong> ìƒíƒœ ë©”ëª¨ë¦¬ $8N\to 2N$ bytes (75% ì ˆê°). ìˆ˜ë ´ í’ˆì§ˆì€ FP32ì™€ ê±°ì˜ ë™ì¼.</p>
  </div>
  <div class="box">
    <h4>Kahan Summation ë³´ì •</h4>
    <div class="formula">$$y=x_\text{update}-c_\text{error}$$</div>
    <div class="formula">$$\theta'=\theta+y$$</div>
    <div class="formula">$$c_\text{error}=(\theta'-\theta)-y$$</div>
    <p class="small"><strong>ì™œ í•„ìš”í•œê°€?</strong> BF16 íŒŒë¼ë¯¸í„°ì— ì‘ì€ ì—…ë°ì´íŠ¸($\sim10^{-5}$)ë¥¼ ë°˜ë³µ ëˆ„ì í•˜ë©´ BF16ì˜ 7ë¹„íŠ¸ ê°€ìˆ˜(mantissa)ë¡œ ì¸í•´ ì‘ì€ ì—…ë°ì´íŠ¸ê°€ <em>ë°˜ì˜¬ë¦¼ìœ¼ë¡œ ì†Œì‹¤</em>ë©ë‹ˆë‹¤. Kahan summationì€ ëˆ„ì  ë¼ìš´ë”© ì˜¤ì°¨ $c$ë¥¼ ë³„ë„ ì €ì¥í•˜ì—¬ ë‹¤ìŒ ì—…ë°ì´íŠ¸ì— ë³´ì •. optimi ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ êµ¬í˜„.</p>
  </div>
</div>

<div class="codebox"># diffusion-pipe: 3ë‹¨ê³„ ì¡°í•© ê°€ëŠ¥
[optimizer]
type = "adamw8bit"         # bitsandbytes 8-bit
# type = "adamw_optimi"    # Kahan summation (optimi)
# type = "stableadamw"     # RMS ì•ˆì •í™” (optimi)
# type = "adamw8bitkahan"  # 8-bit + Kahan + Stable ê²°í•©!

# sd-scripts: bitsandbytes 8-bit
# --optimizer_type=AdamW8bit  (bitsandbytes)
# --optimizer_type=PagedAdamW8bit  (+ CPU offload)</div>

<h4>Muon (GenericOptim) â€” Newton-Schulz ì§êµí™”</h4>
<div class="box" style="border-left:3px solid #e83e8c;margin-bottom:12px">
<p><strong>ìˆ˜í•™ì  ì›ë¦¬:</strong> ê·¸ë˜ë””ì–¸íŠ¸ í–‰ë ¬ $G$ë¥¼ <strong>ê°€ì¥ ê°€ê¹Œìš´ ì§êµ í–‰ë ¬</strong>ë¡œ ì‚¬ì˜í•©ë‹ˆë‹¤. ì´ëŠ” ëª¨ë“  íŠ¹ì´ê°’ì„ 1ë¡œ ì •ê·œí™”í•˜ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤:</p>
<div class="formula">$$G'=UV^\top\qquad\text{where }G=U\Sigma V^\top\text{ (SVD)}$$</div>
<p>SVDëŠ” ë¹„ì‹¸ë¯€ë¡œ, <strong>Newton-Schulz ë°˜ë³µ</strong>ìœ¼ë¡œ ê·¼ì‚¬í•©ë‹ˆë‹¤ ($k=5$ë²ˆ ë°˜ë³µìœ¼ë¡œ ì¶©ë¶„):</p>
<div class="formula">$$X_0=\frac{G}{\|G\|_F},\qquad X_{k+1}=\frac{15}{8}X_k-\frac{5}{4}X_k^3+\frac{3}{8}X_k^5$$</div>
<div class="formula">$$\theta_{t+1}=\theta_t-\eta\cdot X_K$$</div>
<p><strong>í›ˆë ¨ ê´€ì :</strong> ê·¸ë˜ë””ì–¸íŠ¸ì˜ "ë°©í–¥"ë§Œ ì‚¬ìš©í•˜ê³  "í¬ê¸°"ë¥¼ ì •ê·œí™”í•˜ë¯€ë¡œ, ë ˆì´ì–´ ê°„ ê·¸ë˜ë””ì–¸íŠ¸ ìŠ¤ì¼€ì¼ ì°¨ì´ì— ë§¤ìš° ê°•ê±´í•©ë‹ˆë‹¤. diffusion-pipeì˜ GenericOptimì€ 2D+ í…ì„œì— Muon, 1D í…ì„œ(bias, norm)ì— AdamWë¥¼ ìë™ ë¼ìš°íŒ…í•©ë‹ˆë‹¤.</p>
</div>

<h4>ë³€í˜• ë¹„êµ</h4>
<table>
  <thead><tr><th>ë³€í˜•</th><th>í•µì‹¬ ì°¨ì´</th><th>ì½”ë“œ</th></tr></thead>
  <tbody>
    <tr><td><strong>Muon</strong></td><td>ê¸°ë³¸ Newton-Schulz + momentum</td><td><code>momentum_type=muon</code></td></tr>
    <tr><td><strong>AdaMuon</strong></td><td>$v_t$ ì¶”ì ìœ¼ë¡œ ì ì‘ì  ìŠ¤ì¼€ì¼ë§ ì¶”ê°€</td><td><code>momentum_type=adamuon</code></td></tr>
    <tr><td><strong>NorMuon</strong></td><td>Nesterov momentum + ì •ê·œí™”</td><td><code>momentum_type=normuon</code></td></tr>
    <tr><td><strong>Polar Express</strong></td><td>SVD ì§ì ‘ ê³„ì‚° (ì •í™•í•˜ì§€ë§Œ ëŠë¦¼)</td><td><code>momentum_type=polar_express</code></td></tr>
  </tbody>
</table>

<div class="codebox"># diffusion-pipe: GenericOptim ì„¤ì • (configs/*.toml)
[optimizer]
type = "genericoptim"
lr = 0.02                # Muonì€ ì¼ë°˜ì ìœ¼ë¡œ Adamë³´ë‹¤ í° lr
momentum_type = "muon"   # ë˜ëŠ” adamuon, normuon, polar_express
ns_steps = 5             # Newton-Schulz ë°˜ë³µ ìˆ˜
beta = 0.95             # momentum ê³„ìˆ˜
# 2D+ ê°€ì¤‘ì¹˜ â†’ Muon, 1D (bias/norm) â†’ AdamW ìë™ ë¼ìš°íŒ…</div>

<h4>ìˆ˜ë ´ ì†ë„ ë¹„êµ (ì´ë¡ ì )</h4>
<table>
  <thead><tr><th>Optimizer</th><th>ìˆ˜ë ´ë¥ </th><th>ì¡°ê±´</th><th>í™•ì‚° í›ˆë ¨ ì í•©ì„±</th></tr></thead>
  <tbody>
    <tr><td>SGD</td><td>$O(1/\sqrt{T})$</td><td>ë³¼ë¡, Lipschitz</td><td>â–³ ëŠë¦¼, ì•ˆì •ì </td></tr>
    <tr><td>AdamW</td><td>$O(1/\sqrt{T})$</td><td>ë¹„ë³¼ë¡, ì ì‘ì </td><td>â— í‘œì¤€, ë²”ìš©</td></tr>
    <tr><td>Lion</td><td>$O(1/\sqrt{T})$</td><td>ë¶€í˜¸ ê¸°ë°˜, ë©”ëª¨ë¦¬ íš¨ìœ¨</td><td>â—‹ ëŒ€í˜• ë°°ì¹˜ì—ì„œ ìœ ë¦¬</td></tr>
    <tr><td>Prodigy</td><td>$O(d^*/\sqrt{T})$</td><td>ìë™ $d^*$ ì¶”ì •</td><td>â— lr íŠœë‹ ë¶ˆí•„ìš”</td></tr>
    <tr><td>Muon</td><td>ìŠ¤í…ë‹¹ ê³ ë¹„ìš©, ìŠ¤í… ìˆ˜ ê°ì†Œ</td><td>ì§êµí™”ë¡œ ill-conditioning í•´ì†Œ</td><td>â— í° DiTì—ì„œ ê°•ì </td></tr>
  </tbody>
</table>
</section>

<section id="math-e" class="tab-panel" data-tab-group="math-sub">
<h3>E. í›ˆë ¨ ê¸°í˜¸ ì‚¬ì „ â€” ìˆ˜í•™ â†” ì½”ë“œ ì™„ì „ ë§¤í•‘</h3>
<p>ì•„ë˜ í‘œëŠ” í™•ì‚° ëª¨ë¸ í›ˆë ¨ì—ì„œ ë“±ì¥í•˜ëŠ” ì£¼ìš” ìˆ˜í•™ ê¸°í˜¸ë¥¼ ì •ì˜í•˜ê³ , ê·¸ê²ƒì´ <strong>ì‹¤ì œ ì½”ë“œì˜ ì–´ë–¤ ë³€ìˆ˜/ì¸ì</strong>ì— ëŒ€ì‘ë˜ëŠ”ì§€, ê·¸ë¦¬ê³  <strong>ì™œ ê·¸ ê°’ì´ íŠ¹ì • ë²”ìœ„</strong>ì¸ì§€ë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤.</p>

<h4>ëª¨ë¸ &amp; í•™ìŠµ ê¸°ë³¸</h4>
<table>
  <thead><tr><th>ê¸°í˜¸</th><th>ì •ì˜</th><th>ì§ê´€ &amp; ëª¨í‹°ë² ì´ì…˜</th><th>ì½”ë“œ ëŒ€ì‘</th><th>ì „í˜•ì  ê°’</th></tr></thead>
  <tbody>
    <tr><td>$\theta$</td><td>ëª¨ë¸ íŒŒë¼ë¯¸í„° $\theta\in\Theta\subseteq\mathbb{R}^p$</td><td>í•™ìŠµ ëŒ€ìƒ ê°€ì¤‘ì¹˜. UNetì´ë©´ ~860M, DiT(Flux)ì´ë©´ ~12Bê°œì˜ ìŠ¤ì¹¼ë¼.</td><td><code>model.parameters()</code></td><td>â€”</td></tr>
    <tr><td>$g_t$</td><td>$g_t=\nabla_\theta\mathcal{L}(\theta_t)$</td><td>ì†ì‹¤ í•¨ìˆ˜ì˜ ê¸°ìš¸ê¸°. <code>backward()</code>ê°€ ê³„ì‚°í•˜ë©°, í¬ê¸°ì™€ ë°©í–¥ì´ ë‹¤ìŒ ì—…ë°ì´íŠ¸ë¥¼ ê²°ì •.</td><td><code>loss.backward()</code> â†’ <code>p.grad</code></td><td>â€”</td></tr>
    <tr><td>$\eta$</td><td>í•™ìŠµë¥  $\eta\in\mathbb{R}^+$</td><td>íŒŒë¼ë¯¸í„° ê°±ì‹  ë³´í­. ë„ˆë¬´ í¬ë©´ ë°œì‚°, ë„ˆë¬´ ì‘ìœ¼ë©´ ìˆ˜ë ´ ë¶ˆê°€. í™•ì‚° ëª¨ë¸ì—ì„œëŠ” Îµ-prediction Full FT ì‹œ $10^{-6}$ëŒ€, LoRA ì‹œ $10^{-4}$ëŒ€ê°€ í‘œì¤€.</td><td><code>--learning_rate</code></td><td>1e-6~1e-4</td></tr>
    <tr><td>$\beta_1,\beta_2$</td><td>EMA ê°ì‡ ìœ¨</td><td>$\beta_1$: 1ì°¨ ëª¨ë©˜íŠ¸(ë°©í–¥)ì˜ ê´€ì„±. ë†’ì„ìˆ˜ë¡ ê³¼ê±° ê¸°ìš¸ê¸°ì— ë” ì˜ì¡´. $\beta_2$: 2ì°¨ ëª¨ë©˜íŠ¸(ìŠ¤ì¼€ì¼)ì˜ ê´€ì„±. 0.999ë©´ ~1000ìŠ¤í…ì˜ í‰ê·  ë¶„ì‚°.</td><td><code>betas=(0.9, 0.999)</code></td><td>$\beta_1\in[0.9,0.95]$<br>$\beta_2\in[0.99,0.999]$</td></tr>
    <tr><td>$\epsilon_\text{adam}$</td><td>ë¶„ëª¨ ì•ˆì •í™” ìƒìˆ˜</td><td>$\sqrt{\hat v_t}=0$ì¼ ë•Œ 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒì„ ë°©ì§€. BF16ì—ì„œëŠ” 1e-8ì´ underflowí•  ìˆ˜ ìˆì–´ 1e-6ìœ¼ë¡œ ì˜¬ë¦¬ê¸°ë„ í•¨.</td><td><code>eps=1e-8</code></td><td>1e-8~1e-6</td></tr>
    <tr><td>$\lambda$</td><td>Weight Decay ê³„ìˆ˜</td><td>$\theta$ì˜ L2 ë…¸ë¦„ì„ ì¤„ì—¬ ê³¼ì í•© ë°©ì§€. AdamWì—ì„œëŠ” ê·¸ë˜ë””ì–¸íŠ¸ ìŠ¤í…ê³¼ ë…ë¦½ì ìœ¼ë¡œ $\theta\leftarrow(1-\eta\lambda)\theta$ ì ìš©.</td><td><code>weight_decay=0.01</code></td><td>0.0~0.1</td></tr>
  </tbody>
</table>

<h4>í™•ì‚° ê³¼ì •</h4>
<table>
  <thead><tr><th>ê¸°í˜¸</th><th>ì •ì˜</th><th>ì§ê´€ &amp; ëª¨í‹°ë² ì´ì…˜</th><th>ì½”ë“œ ëŒ€ì‘</th><th>ì „í˜•ì  ê°’</th></tr></thead>
  <tbody>
    <tr><td>$\beta_t$</td><td>ìŠ¤í… $t$ì—ì„œì˜ ë…¸ì´ì¦ˆ ì£¼ì… ë¹„ìœ¨</td><td>ê° ì´ì‚° ìŠ¤í…ì—ì„œ ì–¼ë§ˆë‚˜ ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€í• ì§€. linear: 0.0001â†’0.02, cosine: $1-\frac{\bar\alpha_t}{\bar\alpha_{t-1}}$ (ë” ê· ì¼í•œ SNR ë³€í™”)</td><td><code>noise_scheduler.betas</code></td><td>0.0001~0.02</td></tr>
    <tr><td>$\bar\alpha_t$</td><td>$\prod_{s=1}^t(1-\beta_s)$ â€” ëˆ„ì  ì‹ í˜¸ ë³´ì¡´ìœ¨</td><td>$t$ê¹Œì§€ì˜ ì´ ì‹ í˜¸ ì”ì¡´ ë¹„ìœ¨. $\bar\alpha_0=1$ (ì›ë³¸), $\bar\alpha_T\approx 0$ (ìˆœìˆ˜ ë…¸ì´ì¦ˆ). ë³´ê°„ ê³µì‹ $x_t=\sqrt{\bar\alpha_t}x_0+\sqrt{1-\bar\alpha_t}\epsilon$ì˜ í•µì‹¬.</td><td><code>alphas_cumprod[t]</code></td><td>$[1.0\to\approx0.0]$</td></tr>
    <tr><td>$\text{SNR}(t)$</td><td>$\bar\alpha_t/(1-\bar\alpha_t)$</td><td>ì‹ í˜¸ ëŒ€ ì¡ìŒ ì „ë ¥ ë¹„. ëª¨ë“  ê°€ì¤‘ì¹˜ ê¸°ë²•(min-SNR-Î³, debiased ë“±)ì˜ ê¸°ì´ˆ. dB ìŠ¤ì¼€ì¼ë¡œ ë³´ë©´ $\text{SNR}_\text{dB}=10\log_{10}(\text{SNR})$.</td><td><code>(alpha/sigma)**2</code></td><td>$[\infty\to 0]$</td></tr>
    <tr><td>$\sigma(t)$</td><td>Flow Matchingì—ì„œì˜ ë…¸ì´ì¦ˆ ìˆ˜ì¤€ $=t$</td><td>Flow Matchingì—ì„œëŠ” $\sigma=t$ë¡œ ë‹¨ìˆœí™”. Shift ë³€í™˜ $\sigma'=\frac{s\sigma}{1+(s-1)\sigma}$ë¡œ ë¶„í¬ ì¡°ì •.</td><td><code>sigma / timestep</code></td><td>$[0,1]$</td></tr>
    <tr><td>$v_t$</td><td>velocity field $=\epsilon-x_0$ (FM) ë˜ëŠ” $\sqrt{\bar\alpha_t}\epsilon-\sqrt{1-\bar\alpha_t}x_0$ (DDPM v-pred)</td><td>ëª¨ë¸ì´ ì˜ˆì¸¡í•˜ëŠ” ëŒ€ìƒ. í™•ì‚° ê²½ë¡œì˜ "ì†ë„"ë¡œ, ì´ ë°©í–¥ì„ ë”°ë¼ê°€ë©´ ë…¸ì´ì¦ˆì—ì„œ ë°ì´í„°ë¡œ ë„ë‹¬.</td><td><code>target = noise - latent</code></td><td>â€”</td></tr>
  </tbody>
</table>

<h4>LoRA &amp; íŒŒë¼ë¯¸í„° íš¨ìœ¨ì  í•™ìŠµ</h4>
<table>
  <thead><tr><th>ê¸°í˜¸</th><th>ì •ì˜</th><th>ì§ê´€ &amp; ëª¨í‹°ë² ì´ì…˜</th><th>ì½”ë“œ ëŒ€ì‘</th><th>ì „í˜•ì  ê°’</th></tr></thead>
  <tbody>
    <tr><td>$r$</td><td>LoRA í–‰ë ¬ì˜ ë­í¬ $r\ll\min(d_\text{in},d_\text{out})$</td><td>$W\in\mathbb{R}^{d\times d}$ë¥¼ $\Delta W=BA$, $B\in\mathbb{R}^{d\times r}$, $A\in\mathbb{R}^{r\times d}$ë¡œ ê·¼ì‚¬. í•™ìŠµ íŒŒë¼ë¯¸í„°: $d^2\to 2dr$ (ì˜ˆ: $d=4096, r=16$ì´ë©´ $16M\to 131K$).</td><td><code>--network_dim</code> / <code>lora_rank</code></td><td>4~128</td></tr>
    <tr><td>$\alpha_\text{lora}$</td><td>ìŠ¤ì¼€ì¼ë§ ê³„ìˆ˜</td><td>$\Delta W=\frac{\alpha}{r}BA$. $\alpha/r$ì´ ì‹¤ì§ˆì  í•™ìŠµë¥  ìŠ¤ì¼€ì¼. $\alpha=r$ì´ë©´ ìŠ¤ì¼€ì¼ 1.0, $\alpha=r/2$ì´ë©´ 0.5. í•™ìŠµë¥ ê³¼ ê³±í•´ì§€ë¯€ë¡œ lrì„ ì˜¬ë¦¬ëŠ” ê²ƒê³¼ $\alpha$ë¥¼ ì˜¬ë¦¬ëŠ” ê²ƒì€ ê°™ì€ íš¨ê³¼.</td><td><code>--network_alpha</code> / <code>lora_alpha</code></td><td>$r$ì˜ ì ˆë°˜~ë™ì¼</td></tr>
    <tr><td>$\Delta W$</td><td>LoRA ê°€ì¤‘ì¹˜ í–‰ë ¬ $=\frac{\alpha}{r}BA$</td><td>ì›ë³¸ ê°€ì¤‘ì¹˜ $W$ì— ë”í•´ì ¸ $W+\Delta W$ê°€ ìµœì¢… ê°€ì¤‘ì¹˜. í•™ìŠµ ì¤‘ì—ëŠ” $A$: ê°€ìš°ì‹œì•ˆ ì´ˆê¸°í™”, $B$: 0 ì´ˆê¸°í™” â†’ $\Delta W=0$ì—ì„œ ì¶œë°œ (ì›ë³¸ ë³´ì¡´).</td><td><code>lora_up @ lora_down * scale</code></td><td>â€”</td></tr>
  </tbody>
</table>

<h4>í›ˆë ¨ ì œì–´</h4>
<table>
  <thead><tr><th>ê¸°í˜¸</th><th>ì •ì˜</th><th>ì§ê´€ &amp; ëª¨í‹°ë² ì´ì…˜</th><th>ì½”ë“œ ëŒ€ì‘</th><th>ì „í˜•ì  ê°’</th></tr></thead>
  <tbody>
    <tr><td>$N_\text{acc}$</td><td>Gradient Accumulation Steps</td><td>$N_\text{acc}$ë²ˆì˜ ë¯¸ë‹ˆë°°ì¹˜ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ í•©ì‚° í›„ 1íšŒ ì—…ë°ì´íŠ¸. ìœ íš¨ ë°°ì¹˜ = micro_batch Ã— $N_\text{acc}$ Ã— GPU ìˆ˜. VRAM ë¶€ì¡± ì‹œ ìœ íš¨ ë°°ì¹˜ë¥¼ í‚¤ìš°ëŠ” í•µì‹¬ ë„êµ¬.</td><td><code>--gradient_accumulation_steps</code></td><td>1~8</td></tr>
    <tr><td>$\|\nabla\|_\text{clip}$</td><td>ìµœëŒ€ ê·¸ë˜ë””ì–¸íŠ¸ ë…¸ë¦„</td><td>$\|g_t\|>\text{clip}$ì´ë©´ $g_t\leftarrow g_t\cdot\frac{\text{clip}}{\|g_t\|}$. í­ë°œí•˜ëŠ” ê¸°ìš¸ê¸°(gradient explosion) ë°©ì§€. ë„ˆë¬´ ì‘ìœ¼ë©´ í•™ìŠµ ì†ë„ ì €í•˜.</td><td><code>--max_grad_norm</code></td><td>1.0 (ê¸°ë³¸)</td></tr>
    <tr><td>$\sigma_\text{shift}$</td><td>Flow Matching sigma shift</td><td>$\sigma'=\frac{s\sigma}{1+(s-1)\sigma}$ì˜ $s$ ê°’. $s>1$ì´ë©´ ê³ ë…¸ì´ì¦ˆ ë°©í–¥ ì‹œí”„íŠ¸. Flux dev=3.0, schnell=1.0, SD3=3.0.</td><td><code>--discrete_flow_shift</code></td><td>1.0~3.0</td></tr>
    <tr><td>$T$</td><td>ì´ í•™ìŠµ ìŠ¤í… ìˆ˜</td><td>ìŠ¤ì¼€ì¤„ëŸ¬ ì›œì—…/ë””ì¼€ì´ ê³„ì‚°ì˜ ê¸°ì¤€. ë°ì´í„°ì…‹ í¬ê¸°ì™€ ì—í­ ìˆ˜ì˜ ê³±. ì†Œê·œëª¨ LoRA: 500~2000, ëŒ€ê·œëª¨ FT: 10K~100K+.</td><td><code>--max_train_steps</code></td><td>500~100K</td></tr>
    <tr><td>$\gamma_\text{snr}$</td><td>Min-SNR-Î³ì˜ í´ë¦¬í•‘ threshold</td><td>$\text{SNR}(t)>\gamma$ì¸ timestepì˜ ê°€ì¤‘ì¹˜ë¥¼ $\gamma/\text{SNR}$ë¡œ ì¶•ì†Œ. $\gamma=5$ê°€ Pareto ìµœì ì— ê·¼ì ‘ (ë…¼ë¬¸ ì‹¤í—˜). $\gamma=1$ì´ë©´ ë§¤ìš° ê³µê²©ì  í´ë¦¬í•‘.</td><td><code>--snr_gamma</code></td><td>5.0</td></tr>
    <tr><td>$c_\text{huber}$</td><td>Pseudo-Huber lossì˜ í˜•ìƒ íŒŒë¼ë¯¸í„°</td><td>$\mathcal{L}=\sqrt{e^2+c^2}-c$. $c\to 0$: L1 í–‰ë™(ì´ìƒì¹˜ ê°•ê±´), $c\to\infty$: L2 í–‰ë™(íš¨ìœ¨ì  í•™ìŠµ). ì¤‘ê°„ê°’ $c=0.1$ì´ ê· í˜•ì .</td><td><code>--huber_c</code></td><td>0.1</td></tr>
  </tbody>
</table>
</section>

</section>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<!-- TAB 1: í†µí•© í›ˆë ¨ ë£¨í”„ -->
<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<section id="training-loop" class="tab-panel" data-tab-group="master">
<h2>1) í†µí•© í›ˆë ¨ ë£¨í”„ â€” 3ê°œ ì½”ë“œë² ì´ìŠ¤ì˜ ê³µí†µ êµ¬ì¡°</h2>
<p>sampler_siteì˜ "í†µí•© ìƒíƒœì²œì´ ëª¨ë¸"ì²˜ëŸ¼, í›ˆë ¨ë„ ë™ì¼í•œ ë£¨í”„ êµ¬ì¡°ì—ì„œ <strong>loss/optimizer/noise scheduling</strong> í•­ì„ êµì²´í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í†µí•©í•©ë‹ˆë‹¤.</p>

<div class="formula">
$$\theta_{t+1}=\theta_t-\eta\cdot\text{Optimizer}\!\left(\nabla_\theta\,\mathbb{E}_{x_0\sim p_\text{data},\,\epsilon\sim\mathcal{N},\,t\sim p(t)}\left[w(t)\cdot\mathcal{L}(\underbrace{f_\theta(x_t,t)}_{\text{model}},\underbrace{\text{target}(x_0,\epsilon,t)}_{\text{objective}})\right]\right)$$
</div>

<div class="codebox"># í†µí•© í›ˆë ¨ ë£¨í”„ ìŠ¤ì¼ˆë ˆí†¤ (3ê°œ ì½”ë“œë² ì´ìŠ¤ ê³µí†µ êµ¬ì¡°)
for epoch in range(num_epochs):
    for batch in dataloader:
        # â”€â”€ 1. ë°ì´í„° ì¤€ë¹„ â”€â”€
        x_0 = vae.encode(batch["image"])        # latent ì¸ì½”ë”©
        cond = text_encoder(batch["caption"])     # í…ìŠ¤íŠ¸ ì„ë² ë”©
        
        # â”€â”€ 2. ë…¸ì´ì¦ˆ ìŠ¤ì¼€ì¤„ë§ â”€â”€
        t = sample_timestep(strategy)             # timestep ìƒ˜í”Œë§
        epsilon = torch.randn_like(x_0)           # ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ
        x_t = forward_process(x_0, epsilon, t)    # ì •ë°©í–¥ í™•ì‚°
        
        # â”€â”€ 3. ëª¨ë¸ ì˜ˆì¸¡ â”€â”€
        pred = model(x_t, t, cond)                # Îµ, v, ë˜ëŠ” velocity
        target = compute_target(x_0, epsilon, t)  # ì˜ˆì¸¡ ìœ í˜•ì— ë”°ë¥¸ íƒ€ê²Ÿ
        
        # â”€â”€ 4. ì†ì‹¤ ê³„ì‚° â”€â”€
        loss = loss_fn(pred, target)              # MSE / Huber / ...
        loss = apply_weighting(loss, t)           # min-SNR, debiased, ...
        loss = apply_mask(loss, mask)             # ë§ˆìŠ¤í¬ ì ìš© (ì„ íƒ)
        
        # â”€â”€ 5. ì—­ì „íŒŒ & ìµœì í™” â”€â”€
        loss.backward()
        if step % grad_accum == 0:
            clip_grad_norm_(model.parameters(), max_norm)
            optimizer.step()
            lr_scheduler.step()
            optimizer.zero_grad()
        
        # â”€â”€ 6. ì²´í¬í¬ì¸íŠ¸ â”€â”€
        if step % save_interval == 0:
            save_checkpoint(model, optimizer, step)
</div>

<h3>ì½”ë“œë² ì´ìŠ¤ë³„ êµ¬í˜„ ë§¤í•‘</h3>
<table>
  <thead><tr><th>ë£¨í”„ ë‹¨ê³„</th><th>sd-scripts</th><th>diffusion-pipe</th><th>DiffSynth-Studio</th></tr></thead>
  <tbody>
    <tr><td><strong>ë°ì´í„° ì¤€ë¹„</strong></td><td><code>cache_latents</code> + DataLoader</td><td>HF <code>datasets</code> + ì‚¬ì „ ìºì‹±</td><td><code>UnifiedDataset</code> + ì—°ì‚°ì íŒŒì´í”„ë¼ì¸</td></tr>
    <tr><td><strong>Timestep ìƒ˜í”Œë§</strong></td><td><code>--timestep_sampling</code></td><td>ëª¨ë¸ë³„ <code>timestep_sampling()</code></td><td><code>FlowMatchScheduler</code></td></tr>
    <tr><td><strong>ì •ë°©í–¥ í™•ì‚°</strong></td><td>noise scheduler <code>add_noise</code></td><td>ëª¨ë¸ë³„ <code>forward_process</code></td><td><code>scheduler.add_noise()</code></td></tr>
    <tr><td><strong>ëª¨ë¸ ì˜ˆì¸¡</strong></td><td><code>unet()</code> / <code>dit()</code></td><td><code>pipeline.forward()</code></td><td><code>training_module.forward()</code></td></tr>
    <tr><td><strong>ì†ì‹¤ ê³„ì‚°</strong></td><td><code>custom_train_functions</code></td><td><code>BasePipeline.loss()</code></td><td><code>FlowMatchSFTLoss</code></td></tr>
    <tr><td><strong>ìµœì í™”</strong></td><td>HF Accelerate + ì§ì ‘ ìŠ¤ì¼€ì¤„</td><td>DeepSpeed Pipeline</td><td>HF Accelerate</td></tr>
    <tr><td><strong>ì²´í¬í¬ì¸íŠ¸</strong></td><td>safetensors ì§ì ‘ ì €ì¥</td><td>DeepSpeed + safetensors</td><td><code>ModelLogger</code> safetensors</td></tr>
  </tbody>
</table>

<h3>ë ˆì´ì–´ ë¶„í•´ (inferenceì˜ Model/Schedule/Stepper ëŒ€ì‘)</h3>
<table>
  <thead><tr><th>í›ˆë ¨ ë ˆì´ì–´</th><th>í•µì‹¬ ê°ì²´</th><th>ìˆ˜í•™ ì—­í• </th><th>íŠœë‹ í¬ì¸íŠ¸</th></tr></thead>
  <tbody>
    <tr><td>Data Layer</td><td><code>Dataset / DataLoader</code></td><td>$(x_0,c)\sim p_\text{data}$ ìƒ˜í”Œë§</td><td>resolution, AR bucket, caption shuffle</td></tr>
    <tr><td>Noise Layer</td><td><code>NoiseScheduler</code></td><td>$q(x_t|x_0)$ ì •ë°©í–¥ í™•ì‚°</td><td>noise_offset, zero_terminal_snr, discrete_flow_shift</td></tr>
    <tr><td>Model Layer</td><td><code>UNet / DiT</code></td><td>$f_\theta(x_t,t,c)$ ì˜ˆì¸¡</td><td>architecture, adapter, precision</td></tr>
    <tr><td>Loss Layer</td><td><code>LossFunction</code></td><td>$\mathcal{L}(\text{pred},\text{target})$ ê³„ì‚°</td><td>loss_type, weighting, masking</td></tr>
    <tr><td>Optimizer Layer</td><td><code>Optimizer + Scheduler</code></td><td>$\theta_{t+1}=\text{update}(\theta_t,g_t)$</td><td>optimizer_type, lr, betas, weight_decay</td></tr>
    <tr><td>Memory Layer</td><td><code>DeepSpeed / Accelerate</code></td><td>$\text{VRAM} \leq \text{budget}$ ì œì•½</td><td>precision, checkpointing, offload, quantization</td></tr>
  </tbody>
</table>
</section>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<!-- TAB 2: Optimizer Catalog -->
<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<section id="optimizer-catalog" class="tab-panel" data-tab-group="master">
<h2>2) Optimizer Catalog</h2>
<div class="filter">
  <input id="optSearchInput" placeholder="ì˜µí‹°ë§ˆì´ì € ê²€ìƒ‰: adamw, lion, prodigy ..."/>
  <select id="optFamilyFilter">
    <option value="all">ë¶„ë¥˜ ì „ì²´</option>
    <option value="Adam">Adam ê³„ì—´</option>
    <option value="SGD">SGD ê³„ì—´</option>
    <option value="Adaptive">ì ì‘í˜• (D-Adapt/Prodigy)</option>
    <option value="ScheduleFree">Schedule-Free</option>
    <option value="Advanced">ê³ ê¸‰ (Muon/Automagic)</option>
    <option value="Offload">Offload</option>
  </select>
  <select id="optSourceFilter">
    <option value="all">ì½”ë“œë² ì´ìŠ¤ ì „ì²´</option>
    <option value="sd-scripts">sd-scripts</option>
    <option value="diffusion-pipe">diffusion-pipe</option>
    <option value="diffsynth">DiffSynth-Studio</option>
  </select>
</div>
<table>
  <thead><tr><th>Optimizer</th><th>ë¶„ë¥˜</th><th>ìˆ˜ì‹ í•µì‹¬</th><th>ë©”ëª¨ë¦¬</th><th>sd-scripts</th><th>diffusion-pipe</th><th>DiffSynth</th><th>ì£¼ìš” íŒŒë¼ë¯¸í„°</th></tr></thead>
  <tbody>
    <tr class="opt-row" data-name="adamw" data-family="Adam" data-sources="sd-scripts,diffusion-pipe,diffsynth"><td><a class='row-link' href='optimizer/adamw.html'><code>AdamW</code></a></td><td>Adam</td><td>$\hat m/(\sqrt{\hat v}+\epsilon)+\lambda\theta$</td><td>8N</td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td><td><code>lr, betas, weight_decay, eps</code></td></tr>
    <tr class="opt-row" data-name="adamw8bit" data-family="Adam" data-sources="sd-scripts,diffusion-pipe"><td><a class='row-link' href='optimizer/adamw8bit.html'><code>AdamW8bit</code></a></td><td>Adam</td><td>$Q_8(\hat m,\hat v)$ ë™ì ì–‘ìí™”</td><td>2N</td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td><code>lr, betas, weight_decay</code></td></tr>
    <tr class="opt-row" data-name="adamw_optimi" data-family="Adam" data-sources="diffusion-pipe"><td><a class='row-link' href='optimizer/adamw_optimi.html'><code>AdamW (optimi)</code></a></td><td>Adam</td><td>AdamW + Kahan Summation</td><td>8N+</td><td><span class="badge no">âœ—</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td><code>lr, betas, kahan_sum</code></td></tr>
    <tr class="opt-row" data-name="stableadamw" data-family="Adam" data-sources="diffusion-pipe"><td><a class='row-link' href='optimizer/stableadamw.html'><code>StableAdamW</code></a></td><td>Adam</td><td>Stabilized AdamW variance</td><td>8N+</td><td><span class="badge no">âœ—</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td><code>lr, betas, stabilize</code></td></tr>
    <tr class="opt-row" data-name="adamw8bitkahan" data-family="Adam" data-sources="diffusion-pipe"><td><a class='row-link' href='optimizer/adamw8bitkahan.html'><code>AdamW8bitKahan</code></a></td><td>Adam</td><td>8-bit + Kahan ë³´ì •</td><td>2N+</td><td><span class="badge no">âœ—</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td><code>lr, betas, stabilize</code></td></tr>
    <tr class="opt-row" data-name="pagedadamw" data-family="Adam" data-sources="sd-scripts"><td><code>PagedAdamW</code></td><td>Adam</td><td>Paged memory allocation</td><td>8N (paged)</td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td><span class="badge no">âœ—</span></td><td><code>lr, betas, weight_decay</code></td></tr>
    <tr class="opt-row" data-name="lion" data-family="Adam" data-sources="sd-scripts"><td><code>Lion</code></td><td>Adam</td><td>$\text{sign}(\beta_1 m+\cdots)$</td><td>4N</td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td><span class="badge no">âœ—</span></td><td><code>lr, betas, weight_decay</code></td></tr>
    <tr class="opt-row" data-name="lion8bit" data-family="Adam" data-sources="sd-scripts"><td><code>Lion8bit</code></td><td>Adam</td><td>8-bit Lion</td><td>1N</td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td><span class="badge no">âœ—</span></td><td><code>lr, betas</code></td></tr>
    <tr class="opt-row" data-name="sgd" data-family="SGD" data-sources="sd-scripts,diffusion-pipe"><td><code>SGD</code></td><td>SGD</td><td>$\theta-\eta g$</td><td>0</td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td><code>lr, momentum</code></td></tr>
    <tr class="opt-row" data-name="sgdnesterov" data-family="SGD" data-sources="sd-scripts"><td><code>SGDNesterov</code></td><td>SGD</td><td>Nesterov ê°€ì† ëª¨ë©˜í…€</td><td>4N</td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td><span class="badge no">âœ—</span></td><td><code>lr, momentum=0.9</code></td></tr>
    <tr class="opt-row" data-name="adafactor" data-family="Adaptive" data-sources="sd-scripts"><td><code>Adafactor</code></td><td>Adaptive</td><td>í–‰/ì—´ ë¶„í•´ëœ 2ì°¨ ëª¨ë©˜íŠ¸</td><td>~2N (factored)</td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td><span class="badge no">âœ—</span></td><td><code>relative_step, scale_parameter</code></td></tr>
    <tr class="opt-row" data-name="prodigy" data-family="Adaptive" data-sources="sd-scripts,diffusion-pipe"><td><a class='row-link' href='optimizer/prodigy.html'><code>Prodigy</code></a></td><td>Adaptive</td><td>$d_t$ ìë™ LR ì¶”ì •</td><td>8N+</td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td><code>lrâ‰ˆ1.0, d_coef, growth_rate</code></td></tr>
    <tr class="opt-row" data-name="dadaptadam" data-family="Adaptive" data-sources="sd-scripts"><td><code>DAdaptAdam</code></td><td>Adaptive</td><td>D-Adaptation framework</td><td>8N+</td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td><span class="badge no">âœ—</span></td><td><code>lrâ‰ˆ1.0</code></td></tr>
    <tr class="opt-row" data-name="adamwschedulefree" data-family="ScheduleFree" data-sources="sd-scripts"><td><code>AdamWScheduleFree</code></td><td>ScheduleFree</td><td>ë‚´ì¥ ìŠ¤ì¼€ì¤„ (warmupë§Œ)</td><td>8N</td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td><span class="badge no">âœ—</span></td><td><code>lr, betas, warmup_steps</code></td></tr>
    <tr class="opt-row" data-name="muon" data-family="Advanced" data-sources="diffusion-pipe"><td><a class='row-link' href='optimizer/muon.html'><code>Muon (GenericOptim)</code></a></td><td>Advanced</td><td>Newton-Schulz ì§êµí™”</td><td>4N+</td><td><span class="badge no">âœ—</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td><code>momentum_type, ns_steps</code></td></tr>
    <tr class="opt-row" data-name="automagic" data-family="Advanced" data-sources="diffusion-pipe"><td><code>Automagic</code></td><td>Advanced</td><td>ë¶€í˜¸ ì¼ì¹˜ ê¸°ë°˜ ì ì‘ LR</td><td>~2N</td><td><span class="badge no">âœ—</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td><code>lr, factored</code></td></tr>
    <tr class="opt-row" data-name="cpuoffload" data-family="Offload" data-sources="diffusion-pipe"><td><code>CPUOffload</code></td><td>Offload</td><td>ì˜µí‹°ë§ˆì´ì € ìƒíƒœ CPU ì˜¤í”„ë¡œë“œ</td><td>0 (GPU)</td><td><span class="badge no">âœ—</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td><code>inner_optimizer</code></td></tr>
  </tbody>
</table>
<p class="small">ë©”ëª¨ë¦¬: N = íŒŒë¼ë¯¸í„° ìˆ˜. ì˜ˆ: 4N = 4 bytes/param (FP32 ëª¨ë©˜í…€ 1ê°œ). AdamW 8N = m(4N) + v(4N). 8-bitëŠ” Q_8ë¡œ 1/4.</p>
</section>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<!-- TAB 3: LR Scheduler -->
<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<section id="lr-scheduler" class="tab-panel" data-tab-group="master">
<h2>3) LR Scheduler Catalog</h2>
<p>í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ëŠ” í›ˆë ¨ ì¤‘ $\eta(t)$ì˜ ê¶¤ì ì„ ê²°ì •í•©ë‹ˆë‹¤. ì¶”ë¡ ì—ì„œ <code>sigma scheduler</code>ê°€ ë…¸ì´ì¦ˆ ë ˆë²¨ì„ ê²°ì •í–ˆë“¯, ì—¬ê¸°ì„œëŠ” í•™ìŠµë¥  ë ˆë²¨ì„ ê²°ì •í•©ë‹ˆë‹¤.</p>

<table>
  <thead><tr><th>Scheduler</th><th>ìˆ˜ì‹</th><th>sd-scripts</th><th>diffusion-pipe</th><th>DiffSynth</th><th>í•µì‹¬ íŒŒë¼ë¯¸í„°</th></tr></thead>
  <tbody>
    <tr>
      <td><strong>constant</strong></td>
      <td>$$\eta(t)=\eta_0$$</td>
      <td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td>
      <td>â€”</td>
    </tr>
    <tr>
      <td><strong>constant_with_warmup</strong></td>
      <td>$$\eta(t)=\begin{cases}\eta_0\cdot t/T_w&t<T_w\\\eta_0&t\ge T_w\end{cases}$$</td>
      <td><span class="badge yes">âœ“</span></td><td><span class="badge partial">â–³</span></td><td><span class="badge no">âœ—</span></td>
      <td><code>warmup_steps</code></td>
    </tr>
    <tr>
      <td><strong>linear</strong></td>
      <td>$$\eta(t)=\eta_0\left(1-\frac{t-T_w}{T-T_w}\right)$$</td>
      <td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td>
      <td><code>warmup_steps</code></td>
    </tr>
    <tr>
      <td><strong>cosine</strong></td>
      <td>$$\eta(t)=\eta_\text{min}+\frac12(\eta_0-\eta_\text{min})\left(1+\cos\frac{\pi(t-T_w)}{T-T_w}\right)$$</td>
      <td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td><span class="badge no">âœ—</span></td>
      <td><code>warmup_steps</code></td>
    </tr>
    <tr>
      <td><strong>cosine_with_restarts</strong></td>
      <td>$$\eta(t)=\eta_\text{min}+\frac12(\eta_0-\eta_\text{min})\left(1+\cos\frac{\pi\cdot((t-T_w)\bmod T_c)}{T_c}\right)$$</td>
      <td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td><span class="badge no">âœ—</span></td>
      <td><code>warmup_steps, num_cycles</code></td>
    </tr>
    <tr>
      <td><strong>polynomial</strong></td>
      <td>$$\eta(t)=\eta_\text{end}+(\eta_0-\eta_\text{end})\left(1-\frac{t-T_w}{T-T_w}\right)^p$$</td>
      <td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td><span class="badge no">âœ—</span></td>
      <td><code>warmup_steps, power</code></td>
    </tr>
    <tr>
      <td><strong>inverse_sqrt</strong></td>
      <td>$$\eta(t)=\frac{\eta_0}{\sqrt{\max(t,T_s)}}$$</td>
      <td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td><span class="badge no">âœ—</span></td>
      <td><code>timescale</code></td>
    </tr>
    <tr>
      <td><strong>warmup_stable_decay</strong></td>
      <td>$$\eta(t)=\begin{cases}\text{warmup}&t<T_w\\\eta_0&T_w\le t<T_s\\\text{decay}&t\ge T_s\end{cases}$$</td>
      <td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td><span class="badge no">âœ—</span></td>
      <td><code>warmup_steps, decay_steps, min_lr_ratio</code></td>
    </tr>
  </tbody>
</table>

<div class="formula">
$$\text{ìœ íš¨ í•™ìŠµë¥ : }\eta_\text{eff}(t)=\underbrace{\eta_\text{base}}_{\text{--learning\_rate}}\times\underbrace{f_\text{sched}(t)}_{\text{scheduler}}\times\underbrace{s_\text{opt}}_{\text{optimizer ë‚´ë¶€ (Prodigy: }d_t\text{)}}$$
</div>

<h3>Warmupì˜ ìˆ˜í•™ì  ì˜ë¯¸</h3>
<div class="box">
<p>ì´ˆê¸° ê·¸ë˜ë””ì–¸íŠ¸ëŠ” ë¬´ì‘ìœ„ ì´ˆê¸°í™”ì—ì„œ ë¹„ë¡¯ë˜ì–´ <strong>ë¶„ì‚°ì´ í¬ê³  ë°©í–¥ì´ ë¶ˆì•ˆì •</strong>í•©ë‹ˆë‹¤. Warmupì€:</p>
<div class="formula">$$\text{Var}[g_t]\propto\frac{1}{|B|}\quad\Rightarrow\quad\text{ì´ˆê¸° ì†Œ ë°°ì¹˜ì—ì„œëŠ” }\eta\text{ë¥¼ ì¤„ì—¬ì•¼ ì•ˆì •}$$</div>
<p class="small">Adamì˜ bias correction ($1-\beta_2^t$)ì´ ì´ˆê¸°ì— ë¶ˆì¶©ë¶„í•  ë•Œ warmupì´ ì´ë¥¼ ë³´ì™„í•©ë‹ˆë‹¤.</p>
</div>
</section>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<!-- TAB 4: Loss & Weighting -->
<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<section id="loss-catalog" class="tab-panel" data-tab-group="master">
<h2>4) Loss &amp; Weighting ìƒì„¸</h2>

<div class="tabs mini" data-tab-group="loss-sub">
  <button class="tab-btn active" data-tab-group="loss-sub" data-tab-target="loss-base">ê¸°ë³¸ ì†ì‹¤</button>
  <button class="tab-btn" data-tab-group="loss-sub" data-tab-target="loss-weight">ê°€ì¤‘ì¹˜ ì „ëµ</button>
  <button class="tab-btn" data-tab-group="loss-sub" data-tab-target="loss-noise">ë…¸ì´ì¦ˆ ë³€í˜•</button>
  <button class="tab-btn" data-tab-group="loss-sub" data-tab-target="loss-special">íŠ¹ìˆ˜ ì†ì‹¤</button>
</div>

<section id="loss-base" class="tab-panel active" data-tab-group="loss-sub">
<h3>ê¸°ë³¸ ì†ì‹¤ í•¨ìˆ˜</h3>
<table>
  <thead><tr><th>ì†ì‹¤</th><th>ìˆ˜ì‹</th><th>íŠ¹ì„±</th><th>ì½”ë“œ í”Œë˜ê·¸</th></tr></thead>
  <tbody>
    <tr>
      <td><strong>L2 (MSE)</strong></td>
      <td>$$\ell(x,y)=\|x-y\|_2^2$$</td>
      <td>ê¸°ë³¸ê°’. ì´ìƒì¹˜ì— ë¯¼ê°</td>
      <td><code>loss_type=l2</code> (sd-scripts)<br>ê¸°ë³¸ê°’ (diffusion-pipe, DiffSynth)</td>
    </tr>
    <tr>
      <td><strong>L1 (MAE)</strong></td>
      <td>$$\ell(x,y)=\|x-y\|_1$$</td>
      <td>ì´ìƒì¹˜ì— ê°•ê±´. 0ì—ì„œ ë¯¸ë¶„ ë¶ˆì—°ì†</td>
      <td><code>loss_type=l1</code> (sd-scripts)</td>
    </tr>
    <tr>
      <td><strong>Huber</strong></td>
      <td>$$\ell_\delta(x,y)=\begin{cases}\frac12(x-y)^2&|x-y|\le\delta\\\delta(|x-y|-\frac12\delta)&\text{otherwise}\end{cases}$$</td>
      <td>L2ì™€ L1ì˜ í•˜ì´ë¸Œë¦¬ë“œ</td>
      <td><code>loss_type=huber</code> (sd-scripts)</td>
    </tr>
    <tr>
      <td><strong>Pseudo-Huber</strong></td>
      <td>$$\ell_c(x,y)=\sqrt{(x-y)^2+c^2}-c$$</td>
      <td>ë¯¸ë¶„ê°€ëŠ¥í•œ Huber ê·¼ì‚¬. $c\to 0$ì´ë©´ L1, $c\to\infty$ë©´ L2ì— ìˆ˜ë ´</td>
      <td><code>pseudo_huber_c</code> (diffusion-pipe)</td>
    </tr>
  </tbody>
</table>
</section>

<section id="loss-weight" class="tab-panel" data-tab-group="loss-sub">
<h3>Timestep ê°€ì¤‘ì¹˜ ì „ëµ</h3>
<table>
  <thead><tr><th>ì „ëµ</th><th>ê°€ì¤‘ì¹˜ $w(t)$</th><th>íš¨ê³¼</th><th>ì½”ë“œë² ì´ìŠ¤</th></tr></thead>
  <tbody>
    <tr>
      <td><strong>Uniform</strong></td>
      <td>$$w(t)=1$$</td>
      <td>ê¸°ë³¸ê°’. ëª¨ë“  timestep ë™ë“±</td>
      <td>ì „ì²´</td>
    </tr>
    <tr>
      <td><strong>Min-SNR-Î³</strong></td>
      <td>$$w(t)=\frac{\min(\text{SNR}(t),\gamma)}{\text{SNR}(t)}$$</td>
      <td>Î³=5 ê¶Œì¥. ê³  SNR(ì €ë…¸ì´ì¦ˆ) ì˜ì—­ ì–µì œ</td>
      <td><span class="tag sdscripts">sd-scripts</span><span class="tag diffpipe">diffusion-pipe</span></td>
    </tr>
    <tr>
      <td><strong>Debiased (Îµ)</strong></td>
      <td>$$w_\epsilon(t)=\frac{1}{\sqrt{\text{SNR}(t)}}$$</td>
      <td>í¸í–¥ ë³´ì •. Îµ-predictionìš©</td>
      <td><span class="tag sdscripts">sd-scripts</span><span class="tag diffpipe">diffusion-pipe</span></td>
    </tr>
    <tr>
      <td><strong>Debiased (v)</strong></td>
      <td>$$w_v(t)=\frac{1}{\text{SNR}(t)+1}$$</td>
      <td>í¸í–¥ ë³´ì •. v-predictionìš©</td>
      <td><span class="tag sdscripts">sd-scripts</span><span class="tag diffpipe">diffusion-pipe</span></td>
    </tr>
    <tr>
      <td><strong>Ïƒ-sqrt (Flow)</strong></td>
      <td>$$w(t)=\sigma_t^{-2}$$</td>
      <td>Flow matching ëª¨ë¸ì—ì„œ Ïƒ ê¸°ë°˜ ê°€ì¤‘ì¹˜</td>
      <td><span class="tag sdscripts">sd-scripts</span></td>
    </tr>
    <tr>
      <td><strong>Bell-shaped</strong></td>
      <td>$$w(t)=\exp\!\left(-2\left(\frac{t-500}{1000}\right)^2\right)$$</td>
      <td>ê°€ìš°ì‹œì•ˆ ë²¨: ì¤‘ê°„ timestep ì§‘ì¤‘</td>
      <td><span class="tag diffsynth">DiffSynth</span></td>
    </tr>
  </tbody>
</table>
</section>

<section id="loss-noise" class="tab-panel" data-tab-group="loss-sub">
<h3>ë…¸ì´ì¦ˆ ë³€í˜• ê¸°ë²•</h3>
<table>
  <thead><tr><th>ê¸°ë²•</th><th>ìˆ˜ì‹</th><th>íš¨ê³¼</th><th>ì½”ë“œ í”Œë˜ê·¸</th></tr></thead>
  <tbody>
    <tr>
      <td><strong>Noise Offset</strong></td>
      <td>$$\epsilon'=\epsilon+\delta\cdot\mathcal{N}(0,1)\cdot\mathbf{1}_{C\times 1\times 1}$$</td>
      <td>ì±„ë„ë³„ ì „ì—­ ë°ê¸° ì¡°ì • í•™ìŠµ ê°€ëŠ¥</td>
      <td><code>--noise_offset 0.1</code></td>
    </tr>
    <tr>
      <td><strong>Adaptive Noise Scale</strong></td>
      <td>$$\delta_\text{adapt}=\delta\cdot s\cdot\text{mean}(x_0)$$</td>
      <td>ì´ë¯¸ì§€ í‰ê·  ë°ê¸°ì— ë”°ë¼ ì˜¤í”„ì…‹ ìŠ¤ì¼€ì¼</td>
      <td><code>--adaptive_noise_scale</code></td>
    </tr>
    <tr>
      <td><strong>Multi-resolution Noise</strong></td>
      <td>$$\epsilon'=\epsilon+\sum_{l=1}^L d^l\cdot\text{upsample}(\mathcal{N}(0,I_{H/2^l}))$$</td>
      <td>ë‹¤ì¤‘ í•´ìƒë„ í”¼ë¼ë¯¸ë“œ ë…¸ì´ì¦ˆ. ì €ì£¼íŒŒ í•™ìŠµ ê°œì„ </td>
      <td><code>--multires_noise_iterations 6</code></td>
    </tr>
    <tr>
      <td><strong>Input Perturbation (IP)</strong></td>
      <td>$$x_t'=x_t+\gamma\cdot\mathcal{N}(0,I)$$</td>
      <td>ì…ë ¥ì— ì¶”ê°€ ì„­ë™. ë‹¤ì–‘ì„± ì¦ê°€</td>
      <td><code>--ip_noise_gamma 0.1</code></td>
    </tr>
    <tr>
      <td><strong>Zero Terminal SNR</strong></td>
      <td>$$\bar\alpha_T\to 0\quad\Rightarrow\quad\text{SNR}(T)=0$$</td>
      <td>ë§ˆì§€ë§‰ timestepì—ì„œ ìˆœìˆ˜ ë…¸ì´ì¦ˆ ë³´ì¥</td>
      <td><code>--zero_terminal_snr</code></td>
    </tr>
  </tbody>
</table>
</section>

<section id="loss-special" class="tab-panel" data-tab-group="loss-sub">
<h3>íŠ¹ìˆ˜ ì†ì‹¤ (DiffSynth-Studio)</h3>
<table>
  <thead><tr><th>ì†ì‹¤</th><th>ìˆ˜ì‹/ì„¤ëª…</th><th>ìš©ë„</th></tr></thead>
  <tbody>
    <tr>
      <td><strong>FlowMatchSFTLoss</strong></td>
      <td>í‘œì¤€ flow matching MSE + <code>training_weight(t)</code> (bell-shaped ê°€ì¤‘ì¹˜)</td>
      <td>ê¸°ë³¸ SFT (Supervised Fine-Tuning)</td>
    </tr>
    <tr>
      <td><strong>DirectDistillLoss</strong></td>
      <td>$$\mathcal{L}=\text{MSE}(x_\text{student final},x_0)$$<br>ì „ì²´ ì¶”ë¡  ê²½ë¡œ end-to-end</td>
      <td>ì¦ë¥˜ (Distillation)</td>
    </tr>
    <tr>
      <td><strong>TrajectoryImitationLoss</strong></td>
      <td>$$\mathcal{L}=\lambda_1\text{MSE}(\text{traj}_\text{student},\text{traj}_\text{teacher})+\lambda_2\text{LPIPS}(\hat x_0,x_0)$$</td>
      <td>ê²½ë¡œ ëª¨ë°© + ì§€ê° ì†ì‹¤ (Z-Image)</td>
    </tr>
  </tbody>
</table>
</section>
</section>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<!-- TAB 5: Architecture Catalog -->
<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<section id="arch-catalog" class="tab-panel" data-tab-group="master">
<h2>5) Architecture Catalog</h2>
<p>ì¶”ë¡ ì—ì„œ sampler ì¹´íƒˆë¡œê·¸ê°€ ìˆì—ˆë“¯, í›ˆë ¨ì—ì„œëŠ” <strong>ì•„í‚¤í…ì²˜ ì¹´íƒˆë¡œê·¸</strong>ê°€ í•µì‹¬ì…ë‹ˆë‹¤.</p>

<div class="filter">
  <input id="archSearchInput" placeholder="ì•„í‚¤í…ì²˜ ê²€ìƒ‰: flux, sdxl, wan ..."/>
  <select id="archTypeFilter">
    <option value="all">ìœ í˜• ì „ì²´</option>
    <option value="image">Image</option>
    <option value="video">Video</option>
    <option value="both">Image+Video</option>
  </select>
  <select id="archBackboneFilter">
    <option value="all">ë°±ë³¸ ì „ì²´</option>
    <option value="UNet">UNet</option>
    <option value="DiT">DiT</option>
    <option value="MMDiT">MMDiT</option>
  </select>
</div>

<table>
  <thead><tr><th>Architecture</th><th>ìœ í˜•</th><th>ë°±ë³¸</th><th>í™•ì‚° ìœ í˜•</th><th>sd-scripts</th><th>diffusion-pipe</th><th>DiffSynth</th><th>í›ˆë ¨ ëª¨ë“œ</th></tr></thead>
  <tbody>
    <tr class="arch-row" data-name="sd1x" data-type="image" data-backbone="UNet"><td><a class='row-link' href='architecture/sd1x.html'><code>SD 1.x/2.x</code></a></td><td>Image</td><td>UNet</td><td>DDPM (Îµ/v)</td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td><span class="badge no">âœ—</span></td><td>FT, DB, LoRA, TI, CN</td></tr>
    <tr class="arch-row" data-name="sdxl" data-type="image" data-backbone="UNet"><td><a class='row-link' href='architecture/sdxl.html'><code>SDXL</code></a></td><td>Image</td><td>UNet</td><td>DDPM (Îµ/v)</td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td>FT, DB, LoRA, TI, CN</td></tr>
    <tr class="arch-row" data-name="sd3" data-type="image" data-backbone="MMDiT"><td><a class='row-link' href='architecture/sd3.html'><code>SD3 / SD3.5</code></a></td><td>Image</td><td>MMDiT</td><td>Flow Matching</td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td>FT, LoRA</td></tr>
    <tr class="arch-row" data-name="flux" data-type="image" data-backbone="DiT"><td><a class='row-link' href='architecture/flux.html'><code>FLUX.1</code></a></td><td>Image</td><td>DiT</td><td>Flow Matching</td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td><td>FT, LoRA, CN</td></tr>
    <tr class="arch-row" data-name="flux2" data-type="image" data-backbone="DiT"><td><code>FLUX.2</code></td><td>Image</td><td>DiT</td><td>Flow Matching</td><td><span class="badge no">âœ—</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td><td>FT, LoRA</td></tr>
    <tr class="arch-row" data-name="chroma" data-type="image" data-backbone="DiT"><td><code>Chroma</code></td><td>Image</td><td>DiT</td><td>Flow Matching</td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td>FT, LoRA</td></tr>
    <tr class="arch-row" data-name="lumina" data-type="image" data-backbone="DiT"><td><code>Lumina</code></td><td>Image</td><td>DiT</td><td>Flow Matching</td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td>FT, LoRA</td></tr>
    <tr class="arch-row" data-name="hunyuandit" data-type="image" data-backbone="DiT"><td><code>HunyuanDiT</code></td><td>Image</td><td>DiT</td><td>Flow Matching</td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td><span class="badge no">âœ—</span></td><td>LoRA</td></tr>
    <tr class="arch-row" data-name="hunyuanimage" data-type="image" data-backbone="DiT"><td><code>HunyuanImage 2.1</code></td><td>Image</td><td>DiT</td><td>Flow Matching</td><td><span class="badge no">âœ—</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td>FT, LoRA</td></tr>
    <tr class="arch-row" data-name="qwenimage" data-type="image" data-backbone="DiT"><td><code>Qwen-Image</code></td><td>Image</td><td>DiT</td><td>Flow Matching</td><td><span class="badge no">âœ—</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td><td>FT, LoRA</td></tr>
    <tr class="arch-row" data-name="zimage" data-type="image" data-backbone="DiT"><td><code>Z-Image</code></td><td>Image</td><td>DiT</td><td>Flow Matching</td><td><span class="badge no">âœ—</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td><td>FT, LoRA</td></tr>
    <tr class="arch-row" data-name="hidream" data-type="image" data-backbone="DiT"><td><code>HiDream</code></td><td>Image</td><td>DiT</td><td>Flow Matching</td><td><span class="badge no">âœ—</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td>LoRA</td></tr>
    <tr class="arch-row" data-name="auraflow" data-type="image" data-backbone="DiT"><td><code>AuraFlow</code></td><td>Image</td><td>DiT</td><td>Flow Matching</td><td><span class="badge no">âœ—</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td>LoRA</td></tr>
    <tr class="arch-row" data-name="omnigen2" data-type="image" data-backbone="DiT"><td><code>OmniGen2</code></td><td>Image</td><td>DiT</td><td>Flow Matching</td><td><span class="badge no">âœ—</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td>LoRA</td></tr>
    <tr class="arch-row" data-name="cosmos_predict2" data-type="image" data-backbone="DiT"><td><code>Cosmos-Predict2</code></td><td>Image</td><td>DiT</td><td>Flow Matching</td><td><span class="badge no">âœ—</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td>FT, LoRA</td></tr>
    <tr class="arch-row" data-name="anima" data-type="image" data-backbone="DiT"><td><code>Anima</code></td><td>Image</td><td>DiT</td><td>Flow Matching</td><td><span class="badge no">âœ—</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td>FT, LoRA</td></tr>
    <tr class="arch-row" data-name="wan" data-type="video" data-backbone="DiT"><td><a class='row-link' href='architecture/wan.html'><code>Wan 2.1/2.2</code></a></td><td>Video</td><td>DiT</td><td>Flow Matching</td><td><span class="badge no">âœ—</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td><td>FT, LoRA</td></tr>
    <tr class="arch-row" data-name="hunyuanvideo" data-type="video" data-backbone="DiT"><td><code>HunyuanVideo</code></td><td>Video</td><td>DiT</td><td>Flow Matching</td><td><span class="badge no">âœ—</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td>LoRA</td></tr>
    <tr class="arch-row" data-name="hunyuanvideo15" data-type="both" data-backbone="DiT"><td><code>HunyuanVideo 1.5</code></td><td>Image+Video</td><td>DiT</td><td>Flow Matching</td><td><span class="badge no">âœ—</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td>FT, LoRA</td></tr>
    <tr class="arch-row" data-name="ltxvideo" data-type="video" data-backbone="DiT"><td><code>LTX-Video</code></td><td>Video</td><td>DiT</td><td>Flow Matching</td><td><span class="badge no">âœ—</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td>LoRA</td></tr>
    <tr class="arch-row" data-name="cosmos" data-type="video" data-backbone="DiT"><td><code>Cosmos</code></td><td>Video</td><td>DiT</td><td>Flow Matching</td><td><span class="badge no">âœ—</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td>LoRA</td></tr>
  </tbody>
</table>

<h3>LoRA ìˆ˜í•™: ì €ë­í¬ ì ì‘</h3>
<div class="formula">$$W'=W_0+\Delta W=W_0+\frac{\alpha}{r}BA,\quad B\in\mathbb{R}^{d_\text{out}\times r},\;A\in\mathbb{R}^{r\times d_\text{in}}$$</div>
<div class="grid2">
  <div class="box">
    <h3>íŒŒë¼ë¯¸í„° ì ˆê°</h3>
    <div class="formula">$$|\Delta W|=r(d_\text{in}+d_\text{out})\ll d_\text{in}\cdot d_\text{out}$$</div>
    <p class="small">$d=4096, r=16$ì´ë©´: LoRA = $131\text{K}$ vs Full = $16.8\text{M}$ (127ë°° ì ˆê°)</p>
  </div>
  <div class="box">
    <h3>ìœ íš¨ í•™ìŠµë¥ </h3>
    <div class="formula">$$\eta_\text{eff}=\eta_\text{base}\cdot\frac{\alpha}{r}$$</div>
    <p class="small">sd-scripts: <code>network_alpha</code> ê¸°ë³¸ 1 â†’ ì‹¤íš¨ ë°°ìœ¨ $1/r$<br>
    diffusion-pipe/DiffSynth: <code>alpha=rank</code> â†’ ì‹¤íš¨ ë°°ìœ¨ 1</p>
  </div>
</div>

<h3>í›ˆë ¨ ëª¨ë“œ ë¹„êµ</h3>
<table>
  <thead><tr><th>ëª¨ë“œ</th><th>í•™ìŠµ ëŒ€ìƒ</th><th>VRAM</th><th>ì¶œë ¥</th><th>ì½”ë“œë² ì´ìŠ¤</th></tr></thead>
  <tbody>
    <tr><td><strong>Full Fine-Tune</strong></td><td>$\theta$ ì „ì²´</td><td>ë§¤ìš° ë†’ìŒ</td><td>ì „ì²´ ëª¨ë¸</td><td>ì „ì²´</td></tr>
    <tr><td><strong>LoRA</strong></td><td>$B, A$ í–‰ë ¬ë§Œ</td><td>ë‚®ìŒ~ì¤‘ê°„</td><td>ì–´ëŒ‘í„° íŒŒì¼</td><td>ì „ì²´</td></tr>
    <tr><td><strong>DreamBooth</strong></td><td>$\theta$ ì „ì²´ + ì •ê·œí™”</td><td>ë†’ìŒ</td><td>ì „ì²´ ëª¨ë¸</td><td>sd-scripts</td></tr>
    <tr><td><strong>Textual Inversion</strong></td><td>í† í° ì„ë² ë”© $e_*$ ë§Œ</td><td>ë§¤ìš° ë‚®ìŒ</td><td>ì„ë² ë”© íŒŒì¼</td><td>sd-scripts</td></tr>
    <tr><td><strong>ControlNet</strong></td><td>ì¡°ê±´ ì¸ì½”ë” $\theta_\text{cn}$</td><td>ì¤‘ê°„</td><td>ControlNet ëª¨ë¸</td><td>sd-scripts, diffusion-pipe</td></tr>
    <tr><td><strong>DyLoRA</strong></td><td>ê°€ë³€ ë­í¬ $r\in\{1,\dots,R\}$</td><td>ë‚®ìŒ</td><td>ì–´ëŒ‘í„° íŒŒì¼</td><td>sd-scripts</td></tr>
    <tr><td><strong>OFT</strong></td><td>ì§êµ ë³€í™˜ $R\in O(d)$</td><td>ë‚®ìŒ</td><td>ì–´ëŒ‘í„° íŒŒì¼</td><td>sd-scripts</td></tr>
  </tbody>
</table>
</section>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<!-- TAB 6: Hyperparameter ë¸Œë¦¬ì§€ -->
<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<section id="hyperparams" class="tab-panel" data-tab-group="master">
<h2>6) Hyperparameter ë¸Œë¦¬ì§€ â€” ì½”ë“œ íŒŒë¼ë¯¸í„° â†” ìˆ˜ì‹ ë§¤í•‘</h2>
<p>sampler_siteì˜ KSampler ë¸Œë¦¬ì§€ì²˜ëŸ¼, í›ˆë ¨ ì„¤ì •ì˜ ê° íŒŒë¼ë¯¸í„°ê°€ ìˆ˜í•™ì ìœ¼ë¡œ ì–´ë–¤ ì—­í• ì„ í•˜ëŠ”ì§€ ë§¤í•‘í•©ë‹ˆë‹¤.</p>

<div class="tabs mini" data-tab-group="hp-sub">
  <button class="tab-btn active" data-tab-group="hp-sub" data-tab-target="hp-core">í•µì‹¬ íŒŒë¼ë¯¸í„°</button>
  <button class="tab-btn" data-tab-group="hp-sub" data-tab-target="hp-lora">LoRA íŒŒë¼ë¯¸í„°</button>
  <button class="tab-btn" data-tab-group="hp-sub" data-tab-target="hp-noise">ë…¸ì´ì¦ˆ íŒŒë¼ë¯¸í„°</button>
  <button class="tab-btn" data-tab-group="hp-sub" data-tab-target="hp-data">ë°ì´í„° íŒŒë¼ë¯¸í„°</button>
</div>

<section id="hp-core" class="tab-panel active" data-tab-group="hp-sub">
<h3>í•µì‹¬ í›ˆë ¨ íŒŒë¼ë¯¸í„°</h3>
<table>
  <thead><tr><th>íŒŒë¼ë¯¸í„°</th><th>sd-scripts</th><th>diffusion-pipe</th><th>DiffSynth</th><th>ìˆ˜ì‹ ê´€ì </th><th>ê¶Œì¥ ë²”ìœ„</th></tr></thead>
  <tbody>
    <tr><td><strong>learning_rate</strong></td><td><code>--learning_rate 2e-6</code></td><td><code>lr = 1e-4</code></td><td><code>--learning_rate 1e-4</code></td><td>$$\eta\text{ in }\theta_{t+1}=\theta_t-\eta\nabla\mathcal{L}$$</td><td>LoRA: 1e-4~1e-3<br>FT: 1e-6~1e-5</td></tr>
    <tr><td><strong>batch_size</strong></td><td><code>--train_batch_size 1</code></td><td><code>micro_batch_size_per_gpu = 1</code></td><td>DataLoader(batch_size=1)</td><td>$$|B|:\quad \hat g=\frac{1}{|B|}\sum_{i\in B}\nabla\ell_i$$</td><td>1~8 (VRAM ì˜ì¡´)</td></tr>
    <tr><td><strong>grad_accum</strong></td><td><code>--gradient_accumulation_steps</code></td><td><code>gradient_accumulation_steps</code></td><td>Accelerate ì„¤ì •</td><td>$$\text{effBatch}=\text{batch}\times N_\text{acc}\times N_\text{gpu}$$</td><td>1~8</td></tr>
    <tr><td><strong>max_grad_norm</strong></td><td><code>--max_grad_norm 1.0</code></td><td><code>gradient_clipping = 1.0</code></td><td>ê¸°ë³¸ ë¯¸ì§€ì›</td><td>$$g'\gets g\cdot\frac{c}{\max(c,\|g\|)}\quad(c=\text{max\_norm})$$</td><td>1.0</td></tr>
    <tr><td><strong>weight_decay</strong></td><td><code>optimizer_args: weight_decay=0.01</code></td><td><code>weight_decay = 0.01</code></td><td><code>--weight_decay 0.01</code></td><td>$$\theta\gets\theta(1-\eta\lambda)\quad\lambda=\text{wd}$$</td><td>0.01~0.1</td></tr>
    <tr><td><strong>seed</strong></td><td><code>--seed</code></td><td>DS seed</td><td><code>--seed</code></td><td>$\omega\in\Omega$ ê²°ì • â†’ ì¬í˜„ì„±</td><td>ê³ ì • ê¶Œì¥</td></tr>
    <tr><td><strong>epochs / steps</strong></td><td><code>--max_train_epochs / steps</code></td><td><code>epochs / max_steps</code></td><td><code>--num_epochs</code></td><td>$T$: ì´ ìµœì í™” ë°˜ë³µ íšŸìˆ˜</td><td>ì‘ì—… ì˜ì¡´</td></tr>
    <tr><td><strong>mixed_precision</strong></td><td><code>--mixed_precision bf16</code></td><td><code>dtype = "bfloat16"</code></td><td>Accelerate ì„¤ì •</td><td>$$\theta\in\text{FP32/BF16},\; g\in\text{FP16/BF16}$$</td><td>bf16 (A100+)</td></tr>
  </tbody>
</table>
</section>

<section id="hp-lora" class="tab-panel" data-tab-group="hp-sub">
<h3>LoRA ì „ìš© íŒŒë¼ë¯¸í„°</h3>
<table>
  <thead><tr><th>íŒŒë¼ë¯¸í„°</th><th>sd-scripts</th><th>diffusion-pipe</th><th>DiffSynth</th><th>ìˆ˜ì‹ ê´€ì </th></tr></thead>
  <tbody>
    <tr><td><strong>rank (dim)</strong></td><td><code>--network_dim 16</code></td><td><code>rank = 16</code></td><td><code>--lora_rank 32</code></td><td>$$r:\;\Delta W=\frac{\alpha}{r}BA,\;B\in\mathbb{R}^{d\times r}$$</td></tr>
    <tr><td><strong>alpha</strong></td><td><code>--network_alpha 1</code></td><td><code>alpha = rank</code> (ê°•ì œ)</td><td><code>lora_alpha = rank</code></td><td>$$\alpha/r\text{ ê°€ ì‹¤íš¨ ìŠ¤ì¼€ì¼}$$</td></tr>
    <tr><td><strong>dropout</strong></td><td><code>--network_dropout 0.1</code></td><td><code>dropout = 0</code></td><td>ê¸°ë³¸ 0</td><td>$$p:\;\Delta W\cdot\text{Bernoulli}(1-p)$$</td></tr>
    <tr><td><strong>target_modules</strong></td><td><code>--network_args ...</code></td><td>ìë™ (all Linear)</td><td><code>--lora_target_modules auto</code></td><td>$\{W_i:\text{LoRA ì ìš© ë ˆì´ì–´}\}$</td></tr>
    <tr><td><strong>train_unet_only</strong></td><td><code>--network_train_unet_only</code></td><td>ê¸°ë³¸ (TE ìºì‹±)</td><td>ê¸°ë³¸ (TE ìºì‹±)</td><td>$\theta_\text{train}\subset\theta_\text{unet}$</td></tr>
  </tbody>
</table>
</section>

<section id="hp-noise" class="tab-panel" data-tab-group="hp-sub">
<h3>ë…¸ì´ì¦ˆ / Flow Matching íŒŒë¼ë¯¸í„°</h3>
<table>
  <thead><tr><th>íŒŒë¼ë¯¸í„°</th><th>sd-scripts</th><th>diffusion-pipe</th><th>DiffSynth</th><th>ìˆ˜ì‹ ê´€ì </th></tr></thead>
  <tbody>
    <tr><td><strong>noise_offset</strong></td><td><code>--noise_offset 0.1</code></td><td>ë¯¸ì§€ì›</td><td>ë¯¸ì§€ì›</td><td>$$\epsilon'=\epsilon+\delta\mathcal{N}(0,1)\cdot\mathbf{1}_C$$</td></tr>
    <tr><td><strong>discrete_flow_shift</strong></td><td><code>--discrete_flow_shift 3.0</code></td><td>ëª¨ë¸ë³„ ê¸°ë³¸ê°’</td><td>ìŠ¤ì¼€ì¤„ëŸ¬ ë‚´ì¥</td><td>$$t'=\frac{s\cdot t}{1+(s-1)\cdot t}\quad s=\text{shift}$$</td></tr>
    <tr><td><strong>timestep_sampling</strong></td><td><code>--timestep_sampling sigmoid</code></td><td><code>timestep_sampling = logit_normal</code></td><td>FlowMatchScheduler</td><td>$p(t)$ ë¶„í¬ ì„ íƒ</td></tr>
    <tr><td><strong>sigmoid_scale</strong></td><td><code>--sigmoid_scale 1.0</code></td><td>ë¯¸ì§€ì›</td><td>ë¯¸ì§€ì›</td><td>$$t=\sigma(s\cdot z)$$ ì˜ $s$</td></tr>
    <tr><td><strong>min_snr_gamma</strong></td><td><code>--min_snr_gamma 5</code></td><td><code>min_snr_gamma = 5</code></td><td>ë¯¸ì§€ì›</td><td>$$w(t)=\min(\text{SNR},\gamma)/\text{SNR}$$</td></tr>
    <tr><td><strong>v_parameterization</strong></td><td><code>--v_parameterization</code></td><td><code>v_pred = true</code></td><td>ë¯¸ì§€ì› (FMë§Œ)</td><td>$$\text{target}=\sqrt{\bar\alpha}\epsilon-\sqrt{1-\bar\alpha}x_0$$</td></tr>
    <tr><td><strong>weighting_scheme</strong></td><td><code>--weighting_scheme logit_normal</code></td><td>ëª¨ë¸ë³„</td><td>bell-shaped ê¸°ë³¸</td><td>$w(t)$ ê°€ì¤‘ì¹˜ í•¨ìˆ˜</td></tr>
  </tbody>
</table>
</section>

<section id="hp-data" class="tab-panel" data-tab-group="hp-sub">
<h3>ë°ì´í„° íŒŒë¼ë¯¸í„°</h3>
<table>
  <thead><tr><th>íŒŒë¼ë¯¸í„°</th><th>sd-scripts</th><th>diffusion-pipe</th><th>DiffSynth</th><th>íš¨ê³¼</th></tr></thead>
  <tbody>
    <tr><td><strong>resolution</strong></td><td><code>--resolution 1024</code></td><td><code>resolutions = [[1024, 1024]]</code></td><td><code>--max_pixels</code></td><td>í•™ìŠµ ì´ë¯¸ì§€ í•´ìƒë„</td></tr>
    <tr><td><strong>AR bucket</strong></td><td><code>--enable_bucket</code></td><td><code>enable_ar_bucket = true</code></td><td>ë™ì  í•´ìƒë„</td><td>ì¢…íš¡ë¹„ ë³´ì¡´ ë‹¤í•´ìƒë„ í•™ìŠµ</td></tr>
    <tr><td><strong>cache_latents</strong></td><td><code>--cache_latents_to_disk</code></td><td>ìë™ ì‚¬ì „ ìºì‹±</td><td><code>sft:data_process</code> ë‹¨ê³„</td><td>VAE ì¸ì½”ë”© 1íšŒë§Œ ìˆ˜í–‰</td></tr>
    <tr><td><strong>caption_shuffle</strong></td><td><code>--shuffle_caption</code></td><td><code>cache_shuffle_num = 3</code></td><td>ë¯¸ì§€ì›</td><td>íƒœê·¸ ìˆœì„œ ëœë¤í™” â†’ ë°ì´í„° ì¦ê°•</td></tr>
    <tr><td><strong>uncond_fraction</strong></td><td>ë¯¸ì§€ì› (ë³„ë„ êµ¬í˜„)</td><td><code>uncond_fraction = 0.1</code></td><td>ë¯¸ì§€ì›</td><td>CFG ë“œë¡­ì•„ì›ƒ: $P(\text{empty caption})$</td></tr>
    <tr><td><strong>num_repeats</strong></td><td>í´ë”ëª… ì¸ì½”ë”©</td><td><code>num_repeats = 10</code></td><td>ë¯¸ì§€ì›</td><td>ë°ì´í„° ë°˜ë³µ íšŸìˆ˜</td></tr>
    <tr><td><strong>frame_buckets</strong></td><td>ë¯¸ì§€ì›</td><td><code>frame_buckets = [1,33,65]</code></td><td>ì„¤ì • ê°€ëŠ¥</td><td>ë¹„ë””ì˜¤ í”„ë ˆì„ ë²„í‚·íŒ…</td></tr>
  </tbody>
</table>
</section>
</section>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<!-- TAB 7: ë©”ëª¨ë¦¬ ìµœì í™” -->
<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<section id="memory-opt" class="tab-panel" data-tab-group="master">
<h2>7) ë©”ëª¨ë¦¬ ìµœì í™” ì¹´íƒˆë¡œê·¸</h2>
<p>í›ˆë ¨ VRAM ì‚¬ìš©ëŸ‰: $\text{VRAM}=\underbrace{|\theta|}_\text{ëª¨ë¸}+\underbrace{|g|}_\text{ê¸°ìš¸ê¸°}+\underbrace{|m,v|}_\text{ì˜µí‹°ë§ˆì´ì €}+\underbrace{|a|}_\text{í™œì„±í™”}+\underbrace{|x|}_\text{ë°ì´í„°}$</p>

<div class="formula">
$$\text{Full FT VRAM (FP32)}\approx 4|\theta|+4|g|+8|\theta|_\text{states}+|\text{activations}|\approx 16|\theta|+|a|$$
$$\text{LoRA VRAM}\approx 4|\theta|_\text{frozen}+4(r\cdot\Sigma d_i)+\text{optim states for LoRA only}$$
</div>

<table>
  <thead><tr><th>ê¸°ë²•</th><th>VRAM ì ˆê° ëŒ€ìƒ</th><th>ì›ë¦¬</th><th>sd-scripts</th><th>diffusion-pipe</th><th>DiffSynth</th></tr></thead>
  <tbody>
    <tr><td><strong>Mixed Precision (BF16)</strong></td><td>ëª¨ë¸+ê¸°ìš¸ê¸°</td><td>$\theta,g\in\text{BF16}\;(2\text{B/param})$</td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td></tr>
    <tr><td><strong>FP8 Quantization</strong></td><td>ëª¨ë¸ (frozen)</td><td>$\theta_\text{frozen}\in\text{FP8}\;(1\text{B/param})$</td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td></tr>
    <tr><td><strong>NF4 Quantization</strong></td><td>ëª¨ë¸ (frozen)</td><td>$\theta_\text{frozen}\in\text{NF4}\;(0.5\text{B/param})$</td><td><span class="badge no">âœ—</span></td><td><span class="badge partial">â–³</span></td><td><span class="badge no">âœ—</span></td></tr>
    <tr><td><strong>Gradient Checkpointing</strong></td><td>í™œì„±í™”</td><td>ì—­ì „íŒŒ ì‹œ ì¬ê³„ì‚°. $|a|\to O(\sqrt{L})$</td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td></tr>
    <tr><td><strong>Unsloth Checkpointing</strong></td><td>í™œì„±í™”â†’CPU</td><td>í™œì„±í™”ë¥¼ CPU RAMìœ¼ë¡œ ì˜¤í”„ë¡œë“œ</td><td><span class="badge no">âœ—</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge partial">â–³</span></td></tr>
    <tr><td><strong>xformers / SDPA</strong></td><td>ì–´í…ì…˜ ë©”ëª¨ë¦¬</td><td>$O(N)$ vs $O(N^2)$ ì–´í…ì…˜</td><td><span class="badge yes">âœ“</span></td><td>SDPAê¸°ë³¸</td><td>SDPAê¸°ë³¸</td></tr>
    <tr><td><strong>8-bit Optimizer</strong></td><td>ì˜µí‹°ë§ˆì´ì € ìƒíƒœ</td><td>$|m,v|: 8\text{B/param}\to 2\text{B/param}$</td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td></tr>
    <tr><td><strong>Optimizer CPU Offload</strong></td><td>ì˜µí‹°ë§ˆì´ì €â†’CPU</td><td>ìƒíƒœë¥¼ CPU RAMì— ìœ ì§€</td><td><span class="badge no">âœ—</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td></tr>
    <tr><td><strong>Gradient Release</strong></td><td>ê¸°ìš¸ê¸° ë©”ëª¨ë¦¬</td><td>íŒŒë¼ë¯¸í„°ë³„ ì¦‰ì‹œ ì—…ë°ì´íŠ¸ í›„ í•´ì œ</td><td><span class="badge no">âœ—</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td></tr>
    <tr><td><strong>Block Swapping</strong></td><td>ëª¨ë¸ ë¸”ë¡â†’CPU</td><td>DiT ë¸”ë¡ Nê°œë¥¼ CPUë¡œ ìˆœí™˜ êµì²´</td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td></tr>
    <tr><td><strong>Fused Backward Pass</strong></td><td>ê¸°ìš¸ê¸°+ì˜µí‹°ë§ˆì´ì €</td><td>backwardê³¼ optimizer step ê²°í•©</td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td><td><span class="badge no">âœ—</span></td></tr>
    <tr><td><strong>DeepSpeed ZeRO</strong></td><td>ëª¨ë“  ìƒíƒœ ë¶„ì‚°</td><td>ì˜µí‹°ë§ˆì´ì €/ê¸°ìš¸ê¸°/íŒŒë¼ë¯¸í„° GPUê°„ ìƒ¤ë”©</td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td></tr>
    <tr><td><strong>Pipeline Parallelism</strong></td><td>ëª¨ë¸ ë¶„í• </td><td>ëª¨ë¸ì„ GPUê°„ ë ˆì´ì–´ ë‹¨ìœ„ ë¶„í• </td><td><span class="badge no">âœ—</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td></tr>
    <tr><td><strong>Latent Caching</strong></td><td>VAE ë©”ëª¨ë¦¬</td><td>VAE ì¸ì½”ë”© ì‚¬ì „ ìˆ˜í–‰â†’ë””ìŠ¤í¬ ìºì‹œ</td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td></tr>
    <tr><td><strong>TE Output Caching</strong></td><td>í…ìŠ¤íŠ¸ ì¸ì½”ë”</td><td>í…ìŠ¤íŠ¸ ì„ë² ë”© ì‚¬ì „ ìºì‹±</td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td></tr>
    <tr><td><strong>torch.compile</strong></td><td>ì²˜ë¦¬ëŸ‰ (ê°„ì ‘)</td><td>JIT ìµœì í™”ë¡œ ì»¤ë„ í“¨ì „</td><td><span class="badge yes">âœ“</span></td><td><span class="badge yes">âœ“</span></td><td><span class="badge no">âœ—</span></td></tr>
  </tbody>
</table>

<h3>VRAM ì˜ˆì‚° ê³„ì‚°ê¸° (ê°œë…)</h3>
<div class="codebox"># VRAM ì¶”ì • ê³µì‹ (ê°œë…ì )
model_params = 12e9          # ì˜ˆ: 12B íŒŒë¼ë¯¸í„° ëª¨ë¸
dtype_bytes = 2              # BF16: 2, FP32: 4, FP8: 1

# Full Fine-Tune
model_vram = model_params * dtype_bytes          # 24 GB (BF16)
grad_vram = model_params * dtype_bytes           # 24 GB
optim_vram = model_params * 8                    # 96 GB (AdamW FP32 states)
# Total â‰ˆ 144 GB + activations â†’ ë©€í‹° GPU í•„ìˆ˜

# LoRA (r=16, ~0.5% params trainable)
lora_params = model_params * 0.005
frozen_model = model_params * 1    # FP8ì´ë©´ 12 GB
lora_grad = lora_params * dtype_bytes            # 0.12 GB
lora_optim = lora_params * 8                     # 0.48 GB
# Total â‰ˆ 12.6 GB + activations â†’ ë‹¨ì¼ 24GB GPU ê°€ëŠ¥
</div>
</section>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<!-- TAB 8: ì½”ë“œ ë§¤í•‘ -->
<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<section id="code-map" class="tab-panel" data-tab-group="master">
<h2>8) ì½”ë“œ ë§¤í•‘ â€” íŒŒì¼ ê²½ë¡œ ê°€ì´ë“œ</h2>
<p>ê° ì½”ë“œë² ì´ìŠ¤ì—ì„œ í›ˆë ¨ ê´€ë ¨ í•µì‹¬ íŒŒì¼ì˜ ìœ„ì¹˜ì™€ ì—­í• ì„ ë§¤í•‘í•©ë‹ˆë‹¤.</p>

<div class="tabs mini" data-tab-group="code-sub">
  <button class="tab-btn active" data-tab-group="code-sub" data-tab-target="code-sdscripts">sd-scripts</button>
  <button class="tab-btn" data-tab-group="code-sub" data-tab-target="code-diffpipe">diffusion-pipe</button>
  <button class="tab-btn" data-tab-group="code-sub" data-tab-target="code-diffsynth">DiffSynth-Studio</button>
</div>

<section id="code-sdscripts" class="tab-panel active" data-tab-group="code-sub">
<h3>sd-scripts íŒŒì¼ ë§¤í•‘</h3>
<table>
  <thead><tr><th>íŒŒì¼</th><th>ì—­í• </th><th>í•µì‹¬ í•¨ìˆ˜/í´ë˜ìŠ¤</th></tr></thead>
  <tbody>
    <tr><td><code>library/train_util.py</code></td><td>í›ˆë ¨ ì¸ì íŒŒì‹±, ë°ì´í„°ì…‹, ìœ í‹¸ë¦¬í‹°</td><td><code>add_training_arguments()</code>, <code>add_optimizer_arguments()</code></td></tr>
    <tr><td><code>library/custom_train_functions.py</code></td><td>ì†ì‹¤ í•¨ìˆ˜, ê°€ì¤‘ì¹˜, ë…¸ì´ì¦ˆ ë³€í˜•</td><td><code>apply_snr_weight()</code>, <code>apply_debiased_estimation()</code></td></tr>
    <tr><td><code>library/sd3_train_utils.py</code></td><td>SD3/Flux í›ˆë ¨ ìœ í‹¸ë¦¬í‹°</td><td><code>get_sigmas()</code>, <code>compute_loss_weighting()</code></td></tr>
    <tr><td><code>networks/lora.py</code></td><td>LoRA êµ¬í˜„ (SD1.x/SDXL)</td><td><code>LoRANetwork</code>, <code>LoRAModule</code></td></tr>
    <tr><td><code>networks/lora_flux.py</code></td><td>Flux/Chroma LoRA</td><td><code>LoRANetwork</code></td></tr>
    <tr><td><code>networks/lora_sd3.py</code></td><td>SD3 LoRA</td><td><code>LoRANetwork</code></td></tr>
    <tr><td><code>flux_train.py</code></td><td>Flux full fine-tune ì§„ì…ì </td><td><code>train()</code></td></tr>
    <tr><td><code>flux_train_network.py</code></td><td>Flux LoRA í›ˆë ¨ ì§„ì…ì </td><td><code>FluxNetworkTrainer</code></td></tr>
    <tr><td><code>train_network.py</code></td><td>SD/SDXL LoRA ê¸°ë³¸ íŠ¸ë ˆì´ë„ˆ</td><td><code>NetworkTrainer</code></td></tr>
    <tr><td><code>train_db.py</code></td><td>DreamBooth ì§„ì…ì </td><td><code>train()</code></td></tr>
    <tr><td><code>sdxl_train.py</code></td><td>SDXL fine-tune/DB ì§„ì…ì </td><td><code>train()</code></td></tr>
  </tbody>
</table>
</section>

<section id="code-diffpipe" class="tab-panel" data-tab-group="code-sub">
<h3>diffusion-pipe íŒŒì¼ ë§¤í•‘</h3>
<table>
  <thead><tr><th>íŒŒì¼</th><th>ì—­í• </th><th>í•µì‹¬ í•¨ìˆ˜/í´ë˜ìŠ¤</th></tr></thead>
  <tbody>
    <tr><td><code>train.py</code></td><td>ë©”ì¸ í›ˆë ¨ ì§„ì…ì </td><td><code>train()</code>, <code>create_optimizer()</code></td></tr>
    <tr><td><code>models/base.py</code></td><td>íŒŒì´í”„ë¼ì¸ ê¸°ë³¸ í´ë˜ìŠ¤</td><td><code>BasePipeline</code>, <code>ComfyPipeline</code>, <code>loss()</code></td></tr>
    <tr><td><code>models/flux.py</code></td><td>Flux ëª¨ë¸ íŒŒì´í”„ë¼ì¸</td><td><code>FluxPipeline</code></td></tr>
    <tr><td><code>models/wan.py</code></td><td>Wan ë¹„ë””ì˜¤ íŒŒì´í”„ë¼ì¸</td><td><code>WanPipeline</code></td></tr>
    <tr><td><code>models/sdxl.py</code></td><td>SDXL íŒŒì´í”„ë¼ì¸</td><td><code>SDXLPipeline</code></td></tr>
    <tr><td><code>optimizers/generic_optim.py</code></td><td>Muon/AdaMuon/NorMuon ë“±</td><td><code>GenericOptim</code></td></tr>
    <tr><td><code>optimizers/adamw_8bit.py</code></td><td>Kahan ë³´ì • 8-bit Adam</td><td><code>AdamW8bitKahan</code></td></tr>
    <tr><td><code>optimizers/automagic.py</code></td><td>ì ì‘í˜• LR ì˜µí‹°ë§ˆì´ì €</td><td><code>Automagic</code></td></tr>
    <tr><td><code>utils/dataset.py</code></td><td>ë°ì´í„°ì…‹, AR ë²„í‚·, ìºì‹±</td><td><code>Dataset</code>, <code>create_buckets()</code></td></tr>
    <tr><td><code>configs/*.toml</code></td><td>í›ˆë ¨ ì„¤ì • íŒŒì¼</td><td>TOML í¬ë§· ì„¤ì •</td></tr>
  </tbody>
</table>
</section>

<section id="code-diffsynth" class="tab-panel" data-tab-group="code-sub">
<h3>DiffSynth-Studio íŒŒì¼ ë§¤í•‘</h3>
<table>
  <thead><tr><th>íŒŒì¼</th><th>ì—­í• </th><th>í•µì‹¬ í•¨ìˆ˜/í´ë˜ìŠ¤</th></tr></thead>
  <tbody>
    <tr><td><code>diffsynth/diffusion/runner.py</code></td><td>í›ˆë ¨ ë£¨í”„ ì‹¤í–‰ê¸°</td><td><code>launch_training_task()</code></td></tr>
    <tr><td><code>diffsynth/diffusion/training_module.py</code></td><td>í›ˆë ¨ ëª¨ë“ˆ ê¸°ë³¸ í´ë˜ìŠ¤</td><td><code>DiffusionTrainingModule</code></td></tr>
    <tr><td><code>diffsynth/diffusion/loss.py</code></td><td>ì†ì‹¤ í•¨ìˆ˜ ì •ì˜</td><td><code>FlowMatchSFTLoss</code>, <code>DirectDistillLoss</code></td></tr>
    <tr><td><code>diffsynth/diffusion/flow_match.py</code></td><td>Flow matching ìŠ¤ì¼€ì¤„ëŸ¬</td><td><code>FlowMatchScheduler</code>, <code>training_weight()</code></td></tr>
    <tr><td><code>diffsynth/diffusion/parsers.py</code></td><td>CLI ì¸ì íŒŒì‹±</td><td><code>add_training_arguments()</code></td></tr>
    <tr><td><code>diffsynth/diffusion/logger.py</code></td><td>ì²´í¬í¬ì¸íŠ¸ ì €ì¥</td><td><code>ModelLogger</code></td></tr>
    <tr><td><code>diffsynth/core/data/unified_dataset.py</code></td><td>í†µí•© ë°ì´í„°ì…‹</td><td><code>UnifiedDataset</code></td></tr>
    <tr><td><code>diffsynth/core/data/operators.py</code></td><td>ë°ì´í„° ì—°ì‚°ì íŒŒì´í”„ë¼ì¸</td><td><code>LoadImage</code>, <code>ImageCropAndResize</code></td></tr>
    <tr><td><code>diffsynth/utils/lora/</code></td><td>LoRA ìœ í‹¸ë¦¬í‹°</td><td><code>GeneralLoRALoader</code>, <code>merge_lora()</code></td></tr>
    <tr><td><code>diffsynth/models/flux_dit.py</code></td><td>Flux DiT ëª¨ë¸</td><td><code>FluxDiT</code></td></tr>
    <tr><td><code>diffsynth/models/wan_video_dit.py</code></td><td>Wan ë¹„ë””ì˜¤ DiT</td><td><code>WanModel</code></td></tr>
    <tr><td><code>examples/*/model_training/train.py</code></td><td>ì•„í‚¤í…ì²˜ë³„ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸</td><td><code>*TrainingModule</code></td></tr>
  </tbody>
</table>
</section>

<h3 style="margin-top:18px">ì½”ë“œë² ì´ìŠ¤ ì•„í‚¤í…ì²˜ ë¹„êµ</h3>
<div class="grid3">
  <div class="box">
    <h3 style="color:#28a745">sd-scripts</h3>
    <p class="small"><strong>ê°•ì :</strong> ê°€ì¥ ë§ì€ ì˜µí‹°ë§ˆì´ì €/ìŠ¤ì¼€ì¤„ëŸ¬. DDPM ê³„ì—´ (SD1.x/SDXL) ìµœì í™”. DreamBooth/TI ì§€ì›.</p>
    <p class="small"><strong>ë¶„ì‚°í•™ìŠµ:</strong> HF Accelerate + DeepSpeed</p>
    <p class="small"><strong>ì„¤ì •:</strong> CLI ì¸ì + TOML</p>
  </div>
  <div class="box">
    <h3 style="color:#007bff">diffusion-pipe</h3>
    <p class="small"><strong>ê°•ì :</strong> ìµœë‹¤ ì•„í‚¤í…ì²˜ (23+). DeepSpeed Pipeline Parallelism. ê³ ê¸‰ ì˜µí‹°ë§ˆì´ì € (Muon, Automagic). ë¹„ë””ì˜¤ ëª¨ë¸ ì „ë¬¸.</p>
    <p class="small"><strong>ë¶„ì‚°í•™ìŠµ:</strong> DeepSpeed Pipeline + DP</p>
    <p class="small"><strong>ì„¤ì •:</strong> TOML ì„¤ì • íŒŒì¼</p>
  </div>
  <div class="box">
    <h3 style="color:#ffc107">DiffSynth-Studio</h3>
    <p class="small"><strong>ê°•ì :</strong> ê¹”ë”í•œ ì½”ë“œ êµ¬ì¡°. ë°ì´í„° ì—°ì‚°ì íŒŒì´í”„ë¼ì¸. ì¦ë¥˜/ê²½ë¡œëª¨ë°© ì†ì‹¤. 2ë‹¨ê³„ í•™ìŠµ (data_process + train).</p>
    <p class="small"><strong>ë¶„ì‚°í•™ìŠµ:</strong> HF Accelerate + ZeRO</p>
    <p class="small"><strong>ì„¤ì •:</strong> CLI ì¸ì + ì‰˜ ìŠ¤í¬ë¦½íŠ¸</p>
  </div>
</div>
</section>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<!-- SCRIPT -->
<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<script>
function activateTab(group, targetId, updateHash){
  const btns = [...document.querySelectorAll(`.tab-btn[data-tab-group="${group}"]`)];
  const panels = [...document.querySelectorAll(`.tab-panel[data-tab-group="${group}"]`)];
  btns.forEach(b => b.classList.toggle('active', b.dataset.tabTarget === targetId));
  panels.forEach(p => p.classList.toggle('active', p.id === targetId));
  if (updateHash && group === 'master') {
    history.replaceState(null, '', `#${targetId}`);
  }
  if (window.MathJax && window.MathJax.typesetPromise) {
    window.MathJax.typesetPromise();
  }
}

const tabGroups = [...new Set(
  [...document.querySelectorAll('.tab-btn[data-tab-group]')].map(b => b.dataset.tabGroup)
)];
tabGroups.forEach(group => {
  const btns = [...document.querySelectorAll(`.tab-btn[data-tab-group="${group}"]`)];
  if (!btns.length) return;
  btns.forEach(b => {
    b.addEventListener('click', () => activateTab(group, b.dataset.tabTarget, group === 'master'));
  });
  const initial = btns.find(b => b.classList.contains('active')) || btns[0];
  activateTab(group, initial.dataset.tabTarget, false);
});

if (location.hash) {
  const id = location.hash.slice(1);
  const masterBtn = document.querySelector(`.tab-btn[data-tab-group="master"][data-tab-target="${id}"]`);
  if (masterBtn) activateTab('master', id, false);
}

/* â”€â”€ Optimizer filter â”€â”€ */
const optRows = [...document.querySelectorAll('.opt-row')];
const optQ = document.getElementById('optSearchInput');
const optFF = document.getElementById('optFamilyFilter');
const optSF = document.getElementById('optSourceFilter');
function applyOptFilter(){
  if (!optQ || !optFF || !optSF) return;
  const t = optQ.value.trim().toLowerCase();
  const f = optFF.value;
  const s = optSF.value;
  optRows.forEach(r => {
    const okQ = !t || r.dataset.name.toLowerCase().includes(t);
    const okF = f === 'all' || r.dataset.family === f;
    const okS = s === 'all' || (r.dataset.sources && r.dataset.sources.includes(s));
    r.style.display = (okQ && okF && okS) ? '' : 'none';
  });
}
if (optQ) { optQ.addEventListener('input', applyOptFilter); }
if (optFF) { optFF.addEventListener('change', applyOptFilter); }
if (optSF) { optSF.addEventListener('change', applyOptFilter); }

/* â”€â”€ Architecture filter â”€â”€ */
const archRows = [...document.querySelectorAll('.arch-row')];
const archQ = document.getElementById('archSearchInput');
const archTF = document.getElementById('archTypeFilter');
const archBF = document.getElementById('archBackboneFilter');
function applyArchFilter(){
  if (!archQ || !archTF || !archBF) return;
  const t = archQ.value.trim().toLowerCase();
  const tf = archTF.value;
  const bf = archBF.value;
  archRows.forEach(r => {
    const okQ = !t || r.dataset.name.toLowerCase().includes(t);
    const okT = tf === 'all' || r.dataset.type === tf;
    const okB = bf === 'all' || r.dataset.backbone === bf;
    r.style.display = (okQ && okT && okB) ? '' : 'none';
  });
}
if (archQ) { archQ.addEventListener('input', applyArchFilter); }
if (archTF) { archTF.addEventListener('change', applyArchFilter); }
if (archBF) { archBF.addEventListener('change', applyArchFilter); }
</script>

</article></div></body></html>
